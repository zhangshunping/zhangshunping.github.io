<!DOCTYPE html>
<html lang="zh">
  <head>
    <title>
        Ucloud Redis Operator Notes - 背对疾风吧！
      </title>
        <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
    <meta name="renderer" content="webkit">
    <meta http-equiv="Cache-Control" content="no-transform" />
    <meta http-equiv="Cache-Control" content="no-siteapp" />
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    
    <meta name="theme-color" content="#000000" />
    
    <meta http-equiv="window-target" content="_top" />
    
    
    <meta name="description" content="redis-cluster-operator notes" />
    <meta name="generator" content="Hugo 0.79.1 with theme pure" />
    <title>Ucloud Redis Operator Notes - 背对疾风吧！</title>
    
    
    <link rel="stylesheet" href="https://zhangshunping.github.io/css/style.min.7dc20efbc53647d41aa9ddea0c48e59300223d084e66ea0cbe7c30bd88903acc.css">
    
    <link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/9.15.10/styles/github.min.css" async>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css" async>
    <meta property="og:title" content="Ucloud Redis Operator Notes" />
<meta property="og:description" content="redis-cluster-operator notes" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zhangshunping.github.io/2021/04/ucloud-redis-operator-notes/" />
<meta property="article:published_time" content="2021-04-08T15:23:08+08:00" />
<meta property="article:modified_time" content="2021-04-08T15:23:08+08:00" />
<meta itemprop="name" content="Ucloud Redis Operator Notes">
<meta itemprop="description" content="redis-cluster-operator notes">
<meta itemprop="datePublished" content="2021-04-08T15:23:08+08:00" />
<meta itemprop="dateModified" content="2021-04-08T15:23:08+08:00" />
<meta itemprop="wordCount" content="8402">



<meta itemprop="keywords" content="kubernetes,Redis," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Ucloud Redis Operator Notes"/>
<meta name="twitter:description" content="redis-cluster-operator notes"/>

    <!--[if lte IE 9]>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
      <![endif]-->

    <!--[if lt IE 9]>
        <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
      <![endif]-->
  </head>

  
  

  <body class="main-center theme-black" itemscope itemtype="http://schema.org/WebPage"><header class="header" itemscope itemtype="http://schema.org/WPHeader">
    <div class="slimContent">
      <div class="navbar-header">
        <div class="profile-block text-center">
          <a id="avatar" href="https://github.com/zhangshunping" target="_blank">
            <img class="img-circle img-rotate" src="https://zhangshunping.github.io/touxiang.ico" width="200" height="200">
          </a>
          <h2 id="name" class="hidden-xs hidden-sm">张顺平</h2>
          <h3 id="title" class="hidden-xs hidden-sm hidden-md">个人头像</h3>
          <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i>Shanghai, China</small>
        </div><div class="search" id="search-form-wrap">
    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i
                        class="icon icon-search"></i></button>
            </span>
        </div>
        <div class="ins-search">
            <div class="ins-search-mask"></div>
            <div class="ins-search-container">
                <div class="ins-input-wrapper">
                    <input type="text" class="ins-search-input" placeholder="想要查找什么..."
                        x-webkit-speech />
                    <button type="button" class="close ins-close ins-selectable" data-dismiss="modal"
                        aria-label="Close"><span aria-hidden="true">×</span></button>
                </div>
                <div class="ins-section-wrapper">
                    <div class="ins-section-container"></div>
                </div>
            </div>
        </div>
    </form>
</div>
        <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
      </div>
      <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
        <ul class="nav navbar-nav main-nav">
            <li class="menu-item menu-item-home">
                <a href="/">
                    <i class="icon icon-home-fill"></i>
                  <span class="menu-title">Home</span>
                </a>
            </li>
            <li class="menu-item menu-item-archives">
                <a href="/posts/">
                    <i class="icon icon-archives-fill"></i>
                  <span class="menu-title">Archives</span>
                </a>
            </li>
            <li class="menu-item menu-item-categories">
                <a href="/categories/">
                    <i class="icon icon-folder"></i>
                  <span class="menu-title">Categories</span>
                </a>
            </li>
            <li class="menu-item menu-item-tags">
                <a href="/tags/">
                    <i class="icon icon-tags"></i>
                  <span class="menu-title">Tags</span>
                </a>
            </li>
            <li class="menu-item menu-item-about">
                <a href="/about/">
                    <i class="icon icon-cup-fill"></i>
                  <span class="menu-title">About</span>
                </a>
            </li>
        </ul>
      </nav>
    </div>
  </header>

<aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content"><p>Weclome to my Blog!! </p>
            </div>
        </div>
    </div>
</div>

      <div class="widget">
    <h3 class="widget-title"> 分类</h3>
    <div class="widget-body">
        <ul class="category-list">
            <li class="category-list-item"><a href="https://zhangshunping.github.io/categories/gin/" class="category-list-link">gin</a><span class="category-list-count">2</span></li>
            <li class="category-list-item"><a href="https://zhangshunping.github.io/categories/k8s/" class="category-list-link">k8s</a><span class="category-list-count">9</span></li>
            <li class="category-list-item"><a href="https://zhangshunping.github.io/categories/k8s-addon%E5%BC%80%E5%8F%91/" class="category-list-link">k8s-addon开发</a><span class="category-list-count">1</span></li>
            <li class="category-list-item"><a href="https://zhangshunping.github.io/categories/linux/" class="category-list-link">linux</a><span class="category-list-count">4</span></li>
            <li class="category-list-item"><a href="https://zhangshunping.github.io/categories/operator/" class="category-list-link">operator</a><span class="category-list-count">4</span></li>
            <li class="category-list-item"><a href="https://zhangshunping.github.io/categories/redis/" class="category-list-link">redis</a><span class="category-list-count">1</span></li>
            <li class="category-list-item"><a href="https://zhangshunping.github.io/categories/%E4%B8%AA%E4%BA%BA%E5%BC%80%E6%BA%90%E5%B0%8F%E5%B7%A5%E5%85%B7/" class="category-list-link">个人开源小工具</a><span class="category-list-count">5</span></li>
            <li class="category-list-item"><a href="https://zhangshunping.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/" class="category-list-link">云原生</a><span class="category-list-count">11</span></li>
            <li class="category-list-item"><a href="https://zhangshunping.github.io/categories/%E6%97%A5%E5%BF%97/" class="category-list-link">日志</a><span class="category-list-count">1</span></li>
            <li class="category-list-item"><a href="https://zhangshunping.github.io/categories/%E7%9B%91%E6%8E%A7/" class="category-list-link">监控</a><span class="category-list-count">3</span></li>
            <li class="category-list-item"><a href="https://zhangshunping.github.io/categories/%E8%AF%AD%E8%A8%80-golang/" class="category-list-link">语言-golang</a><span class="category-list-count">5</span></li>
        </ul>
    </div>
</div>
      <div class="widget">
    <h3 class="widget-title"> 标签</h3>
    <div class="widget-body">
        <ul class="tag-list">
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/awk/" class="tag-list-link">awk</a><span
                    class="tag-list-count">1</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/gin/" class="tag-list-link">gin</a><span
                    class="tag-list-count">2</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/golang/" class="tag-list-link">golang</a><span
                    class="tag-list-count">11</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/golang-channel/" class="tag-list-link">golang-channel</a><span
                    class="tag-list-count">2</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/iptables/" class="tag-list-link">iptables</a><span
                    class="tag-list-count">2</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/kubernetes/" class="tag-list-link">kubernetes</a><span
                    class="tag-list-count">8</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/linux/" class="tag-list-link">linux</a><span
                    class="tag-list-count">4</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/operator/" class="tag-list-link">operator</a><span
                    class="tag-list-count">3</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/prometheus/" class="tag-list-link">prometheus</a><span
                    class="tag-list-count">1</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/python/" class="tag-list-link">python</a><span
                    class="tag-list-count">1</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/redis/" class="tag-list-link">redis</a><span
                    class="tag-list-count">1</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/rync/" class="tag-list-link">rync</a><span
                    class="tag-list-count">1</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/zabbix/" class="tag-list-link">zabbix</a><span
                    class="tag-list-count">1</span></li>
            
            
            <li class="tag-list-item"><a href="https://zhangshunping.github.io/tags/%E7%9B%91%E6%8E%A7/" class="tag-list-link">监控</a><span
                    class="tag-list-count">2</span></li>
            
        </ul>

    </div>
</div>
      
<div class="widget">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget-body">
        <ul class="recent-post-list list-unstyled no-thumbnail">
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="https://zhangshunping.github.io/2021/04/ucloud-redis-operator-notes/" class="title">Ucloud Redis Operator Notes</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2021-04-08 15:23:08 &#43;0800 CST" itemprop="datePublished">2021-04-08</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="https://zhangshunping.github.io/2021/03/operator-sdk1/" class="title">Operator Sdk1</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2021-03-26 11:17:41 &#43;0800 CST" itemprop="datePublished">2021-03-26</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="https://zhangshunping.github.io/2021/03/kube-eventer-addonsops/" class="title">Kube Eventer二次开发</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2021-03-03 11:38:12 &#43;0800 CST" itemprop="datePublished">2021-03-03</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="https://zhangshunping.github.io/2021/02/redis/" class="title">Redis</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2021-02-22 10:41:45 &#43;0800 CST" itemprop="datePublished">2021-02-22</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="https://zhangshunping.github.io/2021/02/kubernetes-cicd%E8%90%BD%E5%9C%B0/" class="title">CI/CD kubernetes落地</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2021-02-18 18:06:20 &#43;0800 CST" itemprop="datePublished">2021-02-18</time>
                    </p>
                </div>
            </li>
        </ul>
    </div>
</div>
  </div>
</aside>

    
    
<aside class="sidebar sidebar-toc collapse" id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    <h4 class="toc-title">文章目录</h4>
    <nav id="toc" class="js-toc toc">

    </nav>
  </div>
</aside>
<main class="main" role="main"><div class="content">
  <article id="-" class="article article-type-" itemscope
    itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      <h1 itemprop="name">
  <a
    class="article-title"
    href="/2021/04/ucloud-redis-operator-notes/"
    >Ucloud Redis Operator Notes</a
  >
</h1>

      <div class="article-meta">
        
<span class="article-date">
  <i class="icon icon-calendar-check"></i>&nbsp;
<a href="https://zhangshunping.github.io/2021/04/ucloud-redis-operator-notes/" class="article-date">
  <time datetime="2021-04-08 15:23:08 &#43;0800 CST" itemprop="datePublished">2021-04-08</time>
</a>
</span>
<span class="article-category">
  <i class="icon icon-folder"></i>&nbsp;
  <a class="article-category-link" href="/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"> 云原生 </a>
  <a class="article-category-link" href="/categories/k8s/"> k8s </a>
  <a class="article-category-link" href="/categories/operator/"> operator </a>
</span>  
  <span class="article-tag">
    <i class="icon icon-tags"></i>&nbsp;
    <a class="article-tag-link" href="/tags/kubernetes/"> kubernetes </a>
    <a class="article-tag-link" href="/tags/redis/"> Redis </a>
  </span>

        <span class="post-comment"><i class="icon icon-comment"></i>&nbsp;<a href="/2021/04/ucloud-redis-operator-notes/#comments"
            class="article-comment-link">评论</a></span>
		<span class="post-wordcount hidden-xs" itemprop="wordCount">字数统计: 8402字</span>
		<span class="post-readcount hidden-xs" itemprop="timeRequired">阅读时长: 17分 </span>
      </div>
    </div>
    <div class="article-entry marked-body js-toc-content" itemprop="articleBody">
      <p>[toc]</p>
<h2 id="先从crd说起">先从CRD说起</h2>
<p><a href="https://github.com/ucloud/redis-cluster-operator">redis-cluster-operator</a> 项目自定义了两个crd资源 <strong>DistributedRedisCluster, RedisClusterBackup</strong></p>
<p>在已经申请crd资源的k8s集群内可以通过以下命令查看</p>
<pre><code class="language-shell">[root@node01 ~]# kubectl  get crd |grep redis
distributedredisclusters.redis.kun                              2020-10-16T10:58:47Z
redisclusterbackups.redis.kun                                   2020-10-16T10:58:47Z

</code></pre>
<p>也可以通过apiserver 资源查看命令<code>kubectl api-resources|grep drc</code>查看；drc，drcb为<strong>DistributedRedisCluster, RedisClusterBackup</strong>的<strong>shortname</strong>。</p>
<h2 id="operator-保证集群服务配置的最终一致性">operator 保证集群服务配置的最终一致性</h2>
<p>kubernetes operator 是通过list/watch 特定资源，进行一个loop调谐过程，通过比较对应crd自定义资源<strong>drc</strong>的spec和status状态，从而保证资源redis-cluster的最终一致性。</p>
<ol>
<li>operator pod可以通过以下命令查看</li>
</ol>
<pre><code class="language-shell">[root@node01 ~]# kubectl  get pods -nredis-cluster|grep operator
redis-cluster-operator-78b45cdb6b-7lm5z   1/1     Running   3          8d
</code></pre>
<p>**Tips：**这里要说明下operator和k8s，redis-cluster的边界问题，Operator可以理解为只是会控制对应的k8s资源，例如cm，statefulset控制器配置等。Kubernetes和Operator不去介入Redis Cluster的高可用机制，若有冲突以Redis Cluster的为准。</p>
<h2 id="集群管理">集群管理</h2>
<h3 id="一pdb托底redis实例pod可用性"><strong>一、PDB托底redis实例pod可用性</strong></h3>
<p>redis-cluster-operator项目在落地redis-cluster集群的时候，会在k8s内针对每一个pod生成PDB资源<a href="https://jimmysong.io/kubernetes-handbook/concepts/pod-disruption-budget.html">pdb介绍</a>。每一个pdb资源通过<strong>matchLabels</strong>的标签选择方式维护着<strong>statefulset</strong>的可用性。其默认配置maxUnavailable=1，从而保证redis-cluster的在自愿情况（及人工操作)下保证一个statefulset控制的pod副本数最大的不可用数只能为一个，防止误操作导致服务不可用。</p>
<pre><code class="language-shell">[root@node01 ~]# kubectl  get PodDisruptionBudget -nredis-cluster
NAME                               MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
drc-ml-distributedrediscluster-0   N/A             1                 1                     21d
drc-ml-distributedrediscluster-1   N/A             1                 1                     21d
drc-ml-distributedrediscluster-2   N/A             1                 1                     21d

</code></pre>
<h3 id="二redis-cluster主从分布">二、redis-cluster主从分布</h3>
<h4 id="21-pod反亲和">2.1 pod反亲和</h4>
<p>在容器化部署时，同一分片的主从节点Pod不能调度在同一K8S节点，防止由于K8S节点宕机分片整体下线导致数据丢失，使用pod反亲和保证redis实例的主从副本分布在不同的node节点上。</p>
<p>定义好drc之后，redis-cluster-operator会在节点类生成管理redis实列的<strong>statefulset</strong>资源控制器。通过<strong>statefulset</strong>的方式控制数据的有状态存储，通过spec.affinity.podAntiAffinity的pod间的软亲和方式保证主从副本尽量分散到各个不同的node，(因为redis-cluster采用的master-slave机制，保证master和slave节点在不同的节点，从而保证数据的安全性）。</p>
<p>以drc-ml-distributedrediscluster-0 这个statefulset这个资源举个栗子:</p>
<p>其yaml文件定义如下：</p>
<pre><code class="language-yaml"> spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  redis.kun/name: ml-distributedrediscluster
              topologyKey: kubernetes.io/hostname
            weight: 100
</code></pre>
<p>这里使用了k8s的pod之间的反亲和。大致意思就是 drc-ml-distributedrediscluster-0这个statefulset控制器在创建pod的时候，以kubernetes.io/hostname为一个拓扑，及hostname相同的一个node节点为一个拓扑单位，创建的pod的时候最大可能的让两个pod副本不在同一个node上</p>
<h4 id="22-故障之后redis的master节点的重启">2.2 故障之后，redis的master节点的重启</h4>
<ul>
<li>1.在drc对象的statefulset控制器里我们可以看到每次执行stop事件的时候，会执行prestop动作，及执行/conf/shutdown.sh脚本，当reids节点发生故障时，会触发prestop。</li>
</ul>
<pre><code class="language-yaml">        preStop:
            exec:
              command:
              - /bin/sh
              - /conf/shutdown.sh
</code></pre>
<p><code>/conf/shutdown.sh</code>大概意思是，每次执行对pod容器执行stop事件时，都需要执行shutdown.sh，这个showdonw.sh脚本主要去判断自己是否是master角色，如果是是master角色，则向对应的slave节点发送Cluster FAILOVER命令，从而让对应的slave变成master。</p>
<pre><code class="language-shell">### shutdown.sh 脚本内容如下：

#!/bin/sh
CLUSTER_CONFIG=&quot;/data/nodes.conf&quot;
failover() {
	echo &quot;Do CLUSTER FAILOVER&quot;
	masterID=$(cat ${CLUSTER_CONFIG} | grep &quot;myself&quot; | awk '{print $1}')
	echo &quot;Master: ${masterID}&quot;
	slave=$(cat ${CLUSTER_CONFIG} | grep ${masterID} | grep &quot;slave&quot; | awk 'NR==1{print $2}' | sed 's/:6379@16379//')
	echo &quot;Slave: ${slave}&quot;
	password=$(cat /etc/redis_password)
	if [[ -z &quot;${password}&quot; ]]; then
		redis-cli -h ${slave} CLUSTER FAILOVER
	else
		redis-cli -h ${slave} -a &quot;${password}&quot; CLUSTER FAILOVER
	fi
	echo &quot;Wait for MASTER &lt;-&gt; SLAVE syncFinished&quot;
	sleep 20
}
if [ -f ${CLUSTER_CONFIG} ]; then
	cat ${CLUSTER_CONFIG} | grep &quot;myself&quot; | grep &quot;master&quot; &amp;&amp; \
	failover
</code></pre>
<h3 id="三集群伸缩管理">三、集群伸缩管理</h3>
<h4 id="31-redis集群大小管理">3.1. redis集群大小管理</h4>
<p><strong>drc</strong>资源有两个关键资源来控制redic-cluster集群大小：</p>
<p><strong>spec.clusterReplicas： 负责控制着集群的一个master节点对应的slave的副本数 ，原生定义必须 &gt;=1</strong></p>
<p><strong>spec.masterSize： 控制着集群的规模大小 spec.masterSize=3则表示启动了redis-cluster的master节点个数为3</strong></p>
<p>查看redis-cluster对应的drc资源</p>
<pre><code class="language-shell">[root@node01 ~]# kubectl  get drc -nredis-cluster
NAME                         MASTERSIZE   STATUS    AGE
ml-distributedrediscluster   3            Healthy   21d
</code></pre>
<h4 id="32-redis-cluster-扩缩容">3.2 redis-cluster 扩缩容</h4>
<p>修改spce.masterSize 。redis opartor通过内嵌的实现了slot的扩容和缩容策略，具体的可以查看源码分析，这里就不一一例举了。</p>
<p>比如目前的masterSize=3，想扩容及把masterSize改成4即可，想缩容把masterSize改成2即可。</p>
<h4 id="33-reids-slots迁移流程">3.3 reids slots迁移流程</h4>
<ul>
<li>对目标节点发送 <strong>cluster setslot importing</strong> 命令，让目标节点准备导入槽的数据。</li>
<li>对源节点发送 <strong>cluster setslot migrating</strong> 命令，让源节点准备迁出槽的数据。</li>
<li>源节点循环执行 <strong>cluster getkeysinslot</strong> 命令，获取count个属于槽slot的键。</li>
<li>在源节点上执行 <strong>migrate “” 0 keys &lt;keys…&gt;</strong> 命令，把获取的键通过流水线（pipeline）机制批量迁移到目标节点。</li>
<li>重复执行步骤3和步骤4直到槽下所有的键值数据迁移到目标节点。向集群内所有主节点发送cluster setslot node 命令，通知槽分配给目标节点。为了保证槽节点映射变更及时传播，需要遍历发送给所有主节点更新被迁移的槽指向新节点。</li>
</ul>
<p>验证：扩容缩容之后，可以通过cluster nodes或者cluster slots方式查看新建的pods节点是否被分配slots，或者从cluster nodes中去掉信息</p>
<p><img src="ucloud-redis-operator-notes.assets/image-20210421163615744.png" alt="image-20210421163615744"></p>
<h4 id="34-redis-cluster-operator实现的slots迁移源码"><strong>3.4 redis-cluster-operator实现的slots迁移源码</strong></h4>
<p>主要逻辑在<code>redis-cluster-operator/pkg/controller/clustering/rebalance.go</code> 如下：</p>
<p><img src="ucloud-redis-operator-notes.assets/image-20210429160019390.png" alt="image-20210429160019390"></p>
<p>主要逻辑：分别调用了<code>redis-cluster-operator/pkg/redisutil/admin.go</code>中的<code>SetSlots</code>，<code>MigrateKeysInSlot</code>函数。</p>
<p><strong>SetSlots</strong> 分别执行了  <strong>cluster setslot importing</strong>   <strong>cluster setslot migrating</strong>  命令</p>
<p><img src="ucloud-redis-operator-notes.assets/image-20210429160244323.png" alt="image-20210429160244323"></p>
<p><strong>MigrateKeysInSlot</strong>，for循环执行执行 <strong>cluster getkeysinslot</strong> 命令  和执行 <strong>migrate “” 0 keys &lt;keys…&gt;</strong> 命令</p>
<p><img src="ucloud-redis-operator-notes.assets/image-20210429160534296.png" alt="image-20210429160534296"></p>
<p>由此可以看出，redis-operator-cluster对节点的扩缩容，其实也是调用了Redis 本身的Cluster命令。因此用operator触发的slots迁移跟传统的通过redis-cli的方式迁移如出一辙。</p>
<h3 id="四redis-cluster-存储管理">四、redis-cluster 存储管理</h3>
<h4 id="41-pvpvc-pod-持久化">4.1 pv/pvc pod 持久化</h4>
<p>目前生成落地redis-cluster的集群使用的是通过向<strong>openebs</strong>提供的storageclass申请pv，从而实现pvc和pv绑定，达到pod的数据持久化如下。<strong>drc</strong>资源如下，定义storageclassname ，可以通过<code>kubectl  get drc -nredis-cluster -oyaml</code>查看</p>
<pre><code class="language-yaml">  storage:
      class: openebs-hostpath
      size: 10Gi
      type: persistent-claim

</code></pre>
<p>定义完之后提交申请在statefulset资源中生成如下配置</p>
<pre><code class="language-yaml">  volumeClaimTemplates:
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      creationTimestamp: null
      labels:
        managed-by: redis-cluster-operator
        redis.kun/name: ml-distributedrediscluster
        statefulSet: drc-ml-distributedrediscluster-0
      name: redis-data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      ## 向openebs的存储申请pv
      storageClassName: openebs-hostpath
      volumeMode: Filesystem
</code></pre>
<p>值得注意的时候，如果使用pv 的RECLAIM POLICY 尽量使用Retain，不建议使用delete。（由于nfs和openebs存储目前不支持pv的</p>
<p>delete事件，因此这两种引擎使用pv的delete和retain策略的效果一致，都需要手动删除pv.）</p>
<h4 id="42-redis-cluster集群备份">4.2 redis-cluster集群备份</h4>
<p><strong>原生备份方案</strong>：目前ucloud 提供的redis-cluster-operator提供的备份方案支持<strong>本地备份</strong>到pv和<strong>远程备份</strong>到s3，其实现方式都是通过list/watch drcb资源，通过读取drcb资源获取对应的drc集群的一些信息，创建一个job任务进行一次性备份。</p>
<p><strong>不采用原生的备份原因：</strong></p>
<ul>
<li>
<p>原生方案提供的备份方案，在进行rdb dump备份方案时只针对master节点备份，而实际情况下我们备份策略是对slave节点进行备份。</p>
<p><code>redis-cluster-operator/pkg/controller/redisclusterbackup/sync_handler.go</code></p>
<pre><code class="language-go">  ...
  	
for _, node := range cluster.Status.Nodes {
      if node.Role == redisv1alpha1.RedisClusterNodeRoleMaster {
          if i == masterNum {
              break
          }
          folderName, err := backup.RemotePath()
  ...
</code></pre>
<p>如果需要备份slave节点把这段代码改 即可</p>
<pre><code class="language-go">  if node.Role == redisv1alpha1.RedisClusterNodeRoleSlave
</code></pre>
</li>
<li>
<p>本地备份存储的位置不固定</p>
<ul>
<li>
<p>备份节点不固定，虽然可以加nodeselector固定 实现如下</p>
<pre><code class="language-go">func (r *ReconcileRedisClusterBackup) getBackupJob(reqLogger logr.Logger, backup *redisv1alpha1.RedisClusterBackup, cluster *redisv1alpha1.DistributedRedisCluster) (*batchv1.Job, error) {
// add drcb select node to backup rdp files
        jobPostion:=make(map[string]string)
        jobPostion[&quot;drcback&quot;]=&quot;yes&quot;
        
        
    ...
        
    ...
    Spec: batchv1.JobSpec{
                        ActiveDeadlineSeconds: backup.Spec.ActiveDeadlineSeconds,
                        Template: corev1.PodTemplateSpec{
                                Spec: corev1.PodSpec{
                                        NodeSelector: jobPostion,       
    ...                                    
</code></pre>
</li>
<li>
<p>pv不固定，因为触发备份job是通过drcb资源的更新，这样一来生成pv名称会变，会导致redisback的位置不固定</p>
</li>
<li>
<p>不支持cronjob策略，及不能满足日常定时备份策略</p>
</li>
</ul>
</li>
<li>
<p>远程备份到s3原生的备份策略报错，原生包不正确。。。。</p>
</li>
</ul>
<p><strong>自定义脚本备份</strong>：</p>
<p>redis-cluster-operator脚本里备份做了这几件事，参考他的代码实现</p>
<p><img src="ucloud-redis-operator-notes.assets/image-20210421170524348.png" alt="image-20210421170524348"></p>
<p>自定义<code>redisback.sh</code>脚本，备份slave节点，并上传到s3. 内容如下：</p>
<pre><code class="language-shell">k8sconfig=&quot;/root/.kube/config&quot;

slaveip=$(kubectl  --kubeconfig=$k8sconfig get drc -nredis-cluster -oyaml|grep Slave -B 8|grep &quot;ip: &quot;|awk -F ':' '{print $2}')

[ $? -ne 0 ]  &amp;&amp; echo &quot;visit k8s failed&quot; &amp;&amp; exit 1
echo $slaveip

backupdir=&quot;/data/redisbakup&quot;
now=`date '+%Y%m%d_%H'`
backupdir_current=$backupdir/&quot;redis_slave_bak&quot;$now
mkdir -p $backupdir_current


## check 
# 判断磁盘使用百分比, 超过设置值不再执行备份
data_use_max=85
data_use=$(df /data/ | tail -1 | awk '{print $5}'| awk -F'%' '{print $1}')
if [[ $data_use -gt $data_use_max ]]; then
    echo &quot;/data dir use &quot;$data_use&quot;%, exit script&quot;
    exit -1
fi

## 测试可用
for i in $slaveip
do
	redis-cli -r 3 -h $i ping &amp;&gt;/dev/null
	if [ $? -ne 0 ];then
		echo &quot;err: redis instance $i ping out  &quot;
		exit 1
	fi
	
done

##备份 slave rdp 到本地
for i in $slaveip
do
	podname=$(kubectl  get drc -nredis-cluster -oyaml|grep &quot;ip: $i&quot; -A 5|grep podName|awk -F &quot;: &quot; '{print $2}')
	redis-cli --rdb $backupdir_current/&quot;redis.dump.$podname&quot;.rdb -h $i 
done


## 上传到s3
if [ -d &quot;$backupdir_current&quot; ];then
    cd $backupdir
    tar -jcf ${backupdir_current}.tar $backupdir_current
    [ $? -eq 0 ] &amp;&amp; rm -fr ${backupdir_current}
    ## 备份到s3
    /usr/local/bin/aws s3 cp ${backupdir_current}.tar s3:XXXXXXXX  --profile  ops
    if [ $? -ne 0 ];then
	echo &quot;upload to aws fialed&quot;
    fi 
fi

</code></pre>
<p>**Tips：**经过测试当dump 4G的rdb文件时，需要的磁盘的吞吐量大概在50M/s,因此对于redis的dump操作要使用规格比较好的磁盘，并测试下最大的吞吐量。</p>
<h4 id="43-redis-restore">4.3 redis restore</h4>
<p>原生的方案是通过指定pv的方式恢复。</p>
<p>restore.yaml</p>
<pre><code class="language-yaml">apiVersion: redis.kun/v1alpha1
kind: DistributedRedisCluster
metadata:
  annotations:
    # if your operator run as cluster-scoped, add this annotations
    redis.kun/scope: cluster-scoped
  name: example-restore
spec:
  init:
    backupSource:
      name: example-redisclusterbackup
      namespace: default
</code></pre>
<p>不选择用原生的方式restore的原因：</p>
<ol>
<li>
<p>我们用的localpv（如果遇到pv，pvc存在的情况下，restore经常会出现<code>[ x node(s) had volume node affinity conflict]</code>报错，且恢复麻烦；</p>
</li>
<li>
<p>当备份数据在同一个pv中的时候，恢复会出现异常。</p>
</li>
<li>
<p>原生恢复方式，是针对整个集群，而实际restore的场景一般是，负责一个区间的slots的主从宕机的情况。</p>
</li>
</ol>
<p>因此原生的restore_frompvc的方式并不适合我们。</p>
<p><strong>自定义恢复</strong></p>
<p><strong>redis  RDB restore原理：</strong></p>
<p>​     RDB文件的载入工作是在服务器启动时自动执行的，没有专门用于载入RDB文件的命令，只要Redis服务器在启动时检测到RDB文件存在，它就会自动载入RDB文件，服务器在载入RDB文件期间，会一直处于阻塞状态，直到载入工作完成为止。</p>
<p>当appendonly 设置成yes 时候不会将dump.rdb文件中的数据恢复，因此需要将appendonly设置为no</p>
<p>因此在集群额外添加一个cm资源<code>redis-cluster-ml-distributedrediscluster-restore  </code>其内容与operator生成的<code>redis-cluster-ml-distributedrediscluster </code>内容一致，唯一的区别及设置**<code>appendonly=no</code>**</p>
<pre><code class="language-shell">[root@node01 drcb-2021042605-0]# kubectl  get cm -nredis-cluster
NAME                                               DATA   AGE
redis-admin                                        1      192d
redis-cluster-ml-distributedrediscluster           3      50m
redis-cluster-ml-distributedrediscluster-restore   3      42m
redis-cluster-operator-lock                        0      177m
</code></pre>
<p><strong>举个例子：</strong></p>
<p>集群pods如下：</p>
<p><img src="ucloud-redis-operator-notes.assets/image-20210426221335499.png" alt="image-20210426221335499"></p>
<p>当主从实列<code>drc-ml-distributedrediscluster-0-0</code>   和<code>drc-ml-distributedrediscluster-0-1</code>数据丢失后，恢复步骤：</p>
<ul>
<li>
<p>步骤一： 将备份的slave节点的rdb.dump文件拷贝到<code>drc-ml-distributedrediscluster-0-0</code>和<code>drc-ml-distributedrediscluster-0-1</code>对应的pv目录下</p>
</li>
<li>
<p>步骤二： 修改pod对应的 statefulset 资源，drc-ml-distributedrediscluster-0 将cm 设置成 <code>redis-cluster-ml-distributedrediscluster-restore</code> 及关闭appendonly</p>
</li>
<li>
<p>步骤三： 待pod启动完成之后，连进去看keys是否恢复</p>
</li>
<li>
<p>步骤四： 步骤三确认ok之后，重复步骤二，将<code>redis-cluster-ml-distributedrediscluster-restore</code>变成原生<code>redis-cluster-ml-distributedrediscluster</code>，让pod重新启动，pod会顺序启动，到此redis restore完成。</p>
</li>
</ul>
<h4 id="远程备份恢复">远程备份恢复</h4>
<h5 id="bug修复">Bug修复</h5>
<p>原生的程序执行s3 备份和restore的时候，会出现如下等bug，目前已经修复，代码提交到内网gitlab仓库。bug报错如下</p>
<pre><code class="language-shell">phase: Failed
  reason: |-
    GetBucketLocation: RequestError: send request failed
    caused by: Get &quot;https://s3.us-east-1.amazonaws.com.cn/ops-s3-storage?location=&quot;: net/http: invalid header field value &quot;AWS4-HMAC-SHA256 Credential=\x00\xa2\x00Um\x8a\x18\x04\aem\xd2e#8/20210508/us-east-1/s3/aws4_request, SignedHeaders=host;x-amz-content-sha256;x-amz-date, Signature=86b3bc48251cd36900093e10671be2b8b9349b2d23e37752d57ce95e53a59f1d&quot; for key Authorization

</code></pre>
<h5 id="s3-远程backup原理">S3 远程Backup原理</h5>
<p>Operator 会 Watch 集群所有的 RedisClusterBackup 实例变化，当用户提交一个备份的 CR 之后，Operator 会：</p>
<ol>
<li>
<p>创建一个 Kubernetes batch job，根据 Redis 集群分布数，在 job 中注入相同数量的 container，每个 container 向一个 <strong>Slave</strong>（原生是Master节点，现在已经改为Slave节点）发起备份请求，设置开始时间及备份状态。</p>
</li>
<li>
<p>同步完成 RDB 文件后，将 Redis 集群每个分片的 RDB 文件和 cluster-config-file(记录节点slots信息) 上传到对象存储，同时将 CR 的状态置为 Succeeded，设置完成时间。redis集群备份的快照和节点元数据信息，上传到对象存储后，有统一的路径，当前的规则是：redis/{Namespace}/{RedisClusterName}/{StartTime}/{BackupName}-x 比如一个备份一个在 default 命名空间的名为 redis-cluster-test 的 Redis 集群（集群含有三个 master 节点），备份名为 backup , 备份开始时间为 20191101083020这样的格式。</p>
<p>每个master节点备份的快照和节点元数据信息会存储在上述路径，用户可以到相应的 bucket 中查看。执行如下命令接口</p>
</li>
</ol>
<pre><code class="language-shell">[root@node01 MTWB]#   aws s3 ls ops-s3-storage/produce-rediscluster-backup/redis/redis-cluster/ml-rediscluster/20210519081753/  --profile ops
                           PRE 20210519-0017-bak-0/
                           PRE 20210519-0017-bak-1/
                           PRE 20210519-0017-bak-2/
                           PRE 20210519-0017-bak-3/
                           PRE 20210519-0017-bak-4/
                           PRE 20210519-0017-bak-5/

</code></pre>
<h5 id="s3远程restore-原理">s3远程Restore 原理</h5>
<p>从备份恢复和创建步骤不同，分为两阶段，第一阶段同步数据，从快照启动 Master 节点；第二阶段启动 Slave 节点。</p>
<ol>
<li>设置<code>DistributedRedisCluster.Status.Restore.Phase=Running</code>，根据备份信息，创建与备份集群切片数相同的 Statefulset， 设置 Replicas 为 1，只启动 master 节点，注入 <strong>init container，init container</strong> 的作用是拉取对象存储上的快照数据。</li>
<li>等待第1步同步数据完成，master 启动完成后，设置<code>DistributedRedisCluster.Status.Restore.Phase=Restart</code>，移除 init container 后等待节点重启。</li>
<li>第2步完成之后，增加每个分片的副本数调大 Statefulset 的 Replicas，拉起 Slave 节点，设置<code>DistributedRedisCluster.Status.Restore.Phase=Succeeded</code>， 等待所有 Pod 节点状态变为 Runing 之后，设置每个 Statefulset 的 Slave 节点 replicate Master 节点，加入集群。</li>
</ol>
<p><strong>Backup步骤：</strong></p>
<ul>
<li>
<p><code> cd /data/UseDrcbToBakRedis/;bash CronDrcbBak.sh</code>    Crontab 执行脚本任务，根据日期定时在集群创建定时job，备份redis数据到s3上</p>
<pre><code class="language-shell">[root@node01 MTWB]# kubectl get drcb -nredis-cluster
NAME                AGE     PHASE
20210517-0158-bak   2d2h    Succeeded
20210518-0100-bak   27h     Succeeded
20210518-0334-bak   24h     Succeeded
20210518-2334-bak   4h33m   Succeeded
20210518-2343-bak   4h24m   Running
</code></pre>
</li>
<li>
<p><code> cd /data/UseDrcbToBakRedis/;bash CronCheckDrcb.sh</code>  Crontab 定时巡检Drcb 任务是否有异常分三个维度检查  <strong>1.创建任务是否失败，2.执行任务是否失败，3.执行成功后，s3是否存在</strong>。</p>
<p>如有异常则发送报警到飞书群，飞书截图如下：</p>
<p><img src="ucloud-redis-operator-notes.assets/image-20210526112605318.png" alt="image-20210526112605318"></p>
</li>
</ul>
<p><strong>值得注意的是</strong></p>
<p>Backup的pod 运行在  带有 <strong>drcback=yes</strong>的节点，因此需要对node节点打上 <strong>drcback=yes</strong>的label。 对节点的磁盘要求非常高，目前生产redis 执行backup的时候**，磁盘写入i/o达到200MB/s**</p>
<h5 id="restore步骤">Restore步骤：</h5>
<ul>
<li>
<p>在原集群的drc资源里添加如下init配置,这里命名为restore.yaml</p>
<pre><code class="language-yaml"> init:
   backupSource:
     name: 20210516-2329-backup   #drcb 的name
     namespace: redis-cluster
</code></pre>
</li>
<li>
<p>执行<code>apply -f restore.yaml</code>恢复清单，向集群提交restore 资源申请，这个时候会在k8s内创建一个新的drc 集群资源（<strong>新集群的名字尽量与就集群的名字不一样</strong>，因为用的localpv 的方式，所以防止pvc名字一样，指定的文件目录一样）</p>
</li>
<li>
<p><code>kubeclt log -f  operator-pod -nredis-cluster  </code> 查看  operator，当发现如下的日志的时候，说明集群已经恢复完成。</p>
</li>
</ul>
<p><img src="ucloud-redis-operator-notes.assets/image-20210517162047896.png" alt="image-20210517162047896"></p>
<p>​	可以通过<code> redis-cli -h  $Nodeip cluster nodes</code> 查看节点信息，一般情况这个时候只有Master节点存在，没有slave节点，是因为原生的又一个bug，yaml中有init字段后，operator会进行恢复操作，当恢复完成之后，operator很难watch到cr的变化，则不会去执行创建slave节点的操作。当发现如上日志，且 <code>执行cluster nodes</code> 发现slot信息已经完整之后，将<strong>步骤一</strong>添加的init字段删掉，这个时候opeator会感受到cr的变化，执行创建slave节点。</p>
<h3 id="五基于kube-prometheus-operator的监控方案落地">五、基于kube-prometheus operator的监控方案落地</h3>
<h4 id="51-添加redis-metrics抓取">5.1 添加redis metrics抓取</h4>
<p>operator 默认会创建一个<code>servicemonitor</code>的资源,用户<strong>prometheus operator</strong>方案的抓取。</p>
<p><code>redis-cluster-operator/cmd/manager/maing.go</code> 默认定义servicemonitor资源如下</p>
<pre><code class="language-go">   // CreateServiceMonitors will automatically create the prometheus-operator ServiceMonitor resources
        // necessary to configure Prometheus to scrape metrics from this operator.
        services := []*v1.Service{service}
        _, err = metrics.CreateServiceMonitors(cfg, namespace, services)
        if err != nil {
                log.Info(&quot;Could not create ServiceMonitor object&quot;, &quot;error&quot;, err.Error())
                // If this operator is deployed to a cluster without the prometheus-operator running, it will return
                // ErrServiceMonitorNotPresent, which can be used to safely skip ServiceMonitor creation.
                if err == metrics.ErrServiceMonitorNotPresent {
                        log.Info(&quot;Install prometheus-operator in your cluster to create ServiceMonitor objects&quot;, &quot;error&quot;, err.Error())
                }
        }

</code></pre>
<p>可以通过如下命令查看operator 创建redis 生成的<code>servicemonitor</code>资源</p>
<pre><code class="language-shell">[root@node01 manager]# kubectl  get servicemonitor -nredis-cluster 
NAME                             AGE
redis-cluster-operator-monotor   174d
</code></pre>
<p>servicemonitor 通过 namespaceSelector和标签选择selector的方式跟<strong>service</strong>资源关联</p>
<pre><code class="language-shell">   endpoints:
    - interval: 15s
      port: metrics
    namespaceSelector:
      matchNames:
      - redis-cluster
    selector:
      matchLabels:
        app: redis-cluster-monotor
        name: redis-cluster-monotor
</code></pre>
<p>创建redis的监控service 内容如下：</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  labels:
    app: redis-cluster-monotor
    name: redis-cluster-monotor
  name: ml-redis-cluster-monotor
  namespace: redis-cluster
spec:
  ports:
  - name: metrics
    port: 9100
    protocol: TCP
    targetPort: 9100
  selector:
    managed-by: redis-cluster-operator
    redis.kun/name: ml-distributedrediscluster
  sessionAffinity: None
  type: ClusterIP
</code></pre>
<p>注意的是如果要开启监控，那么redis的<strong>drc</strong>资源里必须添加<strong>monitor选项</strong>,内容如下：</p>
<pre><code class="language-yaml">  monitor:
    image: oliver006/redis_exporter
    prometheus:
      port: 9100
    resources: {}

</code></pre>
<h4 id="52-添加prometheus-rules-监控报警规则">5.2 添加prometheus Rules 监控报警规则</h4>
<p>基于prometheus operator 方案中，获取prometheus rules的规则是通过定义在<code>Prometheus</code>资源中,可以通过</p>
<p><code>kubectl  get prometheus -nmonitoring k8s  -oyaml</code>查看 ，及通过ruleSelector选项选择PrometheusRule资源，且标签为<code>prometheus: k8s</code> 和 <code>role: alert-rules</code></p>
<pre><code class="language-yaml"> ruleSelector:
    matchLabels:
      prometheus: k8s
      role: alert-rules

</code></pre>
<p>定义<code>redis-cluster-rule.yaml</code>示例如下：</p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: k8s
    role: alert-rules
  name: redis-cluster-rules
  namespace: monitoring
spec:
  groups:
  - name: redis-cluster.rules
    rules:
    - alert: redis down
      annotations:
        description: redis instance is down
        summary: redis down (instance {{ $labels.instance }})
        value: '{{ $value }}'
      expr: redis_up == 0
      for: 30s
      labels:
        name: redis
        severity: error
...

</code></pre>
<p><strong>TIPS</strong>：operator默认给prometheus实例的serviceaccount是放开了权限，当servicemonitor，svc设置完之后，等待一段时间发现prometheus 的targets无显示添加的监控项，可以看下prometheus的logs查找，一般情况下可以看看binding的clusterrole或者role是否有访问集群资源的权限。</p>
<p>目前对redis集群的监控方案，包括redis的健康状态，redis-cluster的主从状态，数据dump状态进行监控，具体的可以通过如下命令查看</p>
<pre><code class="language-shell"> kubectl  get prometheusrules -nmonitoring redis-cluster-rules -oyaml
</code></pre>
<h3 id="六redis-cluster集群使用过程中的注意事项">六、redis-cluster集群使用过程中的注意事项</h3>
<h4 id="61-redis的linux系统优化">6.1 Redis的Linux系统优化</h4>
<ul>
<li>
<p><strong>vm.overcommit_memory</strong></p>
<p>设置vm.overcommit_memory=1，防止极端情况下，会造成fork失败。</p>
<pre><code>echo &quot;vm.overcommit_memory=1&quot; &gt;&gt; /etc/sysctl.conf
sysctl vm.overcommit_memory=1
</code></pre>
<p><strong>说明：</strong></p>
<pre><code>vm.overcommit_memoy=0 ：表示内核将检查是否有足够的可用内存。如果有足够的可用内存，内存申请通过，否则内存申请失败，并把错误返回给应用进程
  
vm.overcommit_memoy=1 ：表示内核允许超量使用内存直到用完为止
  
vm.overcommit_memoy=2 ：表示内核决不过量的(“never overcommit”)使用内存，即系统整个内存地址空间不能超过swap+50%的RAM值，50%是overcommit_ratio默认值，此参数同样支持修改
</code></pre>
<p>如果vm.overcommit_memory=0，代表如果没有可用内存，就申请内存失败，对应到Redis就是fork执行失败，在Redis的日志会出现：</p>
<pre><code>Cannot allocate memory
</code></pre>
<p>Redis建议把这个值设置为1，是为了让fork能够在低内存下也执行成功。</p>
</li>
<li>
<p><strong>Transparent Huge Pages</strong></p>
</li>
</ul>
<p>Redis建议修改Transparent Huge Pages (THP)的相关配置，Linux kernel在2.6.38内核增加了Transparent Huge Pages (THP)特性 ，支持大内存页(2MB)分配，默认开启。当开启时可以降低fork子进程的速度，但fork之后，每个内存页从原来4KB变为2MB，会大幅增加重写期间父进程内存消耗。同时每次写命令引起的复制内存页单位放大了512倍，会拖慢写操作的执行时间，导致大量写操作慢查询。例如简单的incr命令也会出现在慢查询中。因此Redis日志中建议将此特性进行禁用，禁用方法如下：</p>
<pre><code class="language-shell">echo never &gt;  /sys/kernel/mm/transparent_hugepage/enabled
</code></pre>
<ul>
<li>
<p>somaxconn</p>
<p>在/etc/sysctl.conf中添加,修改默认somaxconn=128值</p>
<p><code>net.core.somaxconn = 65535</code></p>
</li>
</ul>

    </div>
    <div class="article-footer">
<blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接: </strong>
      <a href="https://zhangshunping.github.io/2021/04/ucloud-redis-operator-notes/" title="Ucloud Redis Operator Notes" target="_blank" rel="external">https://zhangshunping.github.io/2021/04/ucloud-redis-operator-notes/</a>
    </li>
    <li class="post-copyright-license">
      <strong>License：</strong><a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN</a>
    </li>
  </ul>
</blockquote>

<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://github.com/zhangshunping" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="https://zhangshunping.github.io/touxiang.ico" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://github.com/zhangshunping" target="_blank"><span class="text-dark">张顺平</span><small class="ml-1x">个人头像</small></a></h3>
        <div>Good Good Study, Day Day Up~</div>
      </div>
    </figure>
  </div>
</div>
    </div>
  </article>
<section id="comments">
</section>

</div><nav class="bar bar-footer clearfix" data-stick-bottom>
    <div class="bar-inner">
        <ul class="pager pull-left">
            <li class="prev">
                <a href="https://zhangshunping.github.io/2021/03/operator-sdk1/" title="Operator Sdk1"><i
                        class="icon icon-angle-left"
                        aria-hidden="true"></i><span>&nbsp;&nbsp;下一篇</span></a>
            </li>
            
            <li class="toggle-toc">
                <a class="toggle-btn collapsed" data-toggle="collapse" href="#collapseToc" aria-expanded="false"
                    title="文章目录" role="button">
                    <span>[&nbsp;</span><span>文章目录</span>
                    <i class="text-collapsed icon icon-anchor"></i>
                    <i class="text-in icon icon-close"></i>
                    <span>]</span>
                </a>
            </li>
        </ul>
        <div class="bar-right">
            <div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter"
                data-mobile-sites="weibo,qq,qzone"></div>
        </div>
    </div>
</nav>

</main><footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
<ul class="social-links">
    <li><a href="https://github.com/zhangshunping" target="_blank" title="github" data-toggle=tooltip data-placement=top >
            <i class="icon icon-github"></i></a></li>
    <li><a href="https://zhangshunping.github.io/index.xml" target="_blank" title="rss" data-toggle=tooltip data-placement=top >
            <i class="icon icon-rss"></i></a></li>
</ul>
  <div class="copyright">
    &copy;2017  -
    2021
    <div class="publishby">
        Theme by <a href="https://github.com/xiaoheiAh" target="_blank"> xiaoheiAh </a>base on<a href="https://github.com/xiaoheiAh/hugo-theme-pure" target="_blank"> pure</a>.
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
            showMathMenu: false, //disables context menu
            tex2jax: {
            inlineMath: [ ['$','$'], ['\\(','\\)'] ]
           }
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>
<script>
    window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>
<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/highlight.min.js"></script>
<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/languages/python.min.js" defer></script>
<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/languages/javascript.min.js" defer></script><script>
    hljs.configure({
        tabReplace: '    ', 
        classPrefix: ''     
        
    })
    hljs.initHighlightingOnLoad();
</script>
<script src="https://zhangshunping.github.io/js/application.min.bdeb64b910570b6c41badc6a05b7afb0c8ad9efd8525de3c7257d59e786326a3.js"></script>
<script src="https://zhangshunping.github.io/js/plugin.min.51ff8c7317566f82259170fa36e09c4493adc9b9378b427a01ad3f017ebac7dd.js"></script>

<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: '文章',
                PAGES: '页面',
                CATEGORIES: '分类',
                TAGS: '标签',
                UNTITLED: '(未命名)',
            },
            ROOT_URL: 'https:\/\/zhangshunping.github.io',
            CONTENT_URL: 'https:\/\/zhangshunping.github.io\/searchindex.json ',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script type="text/javascript" src="https://zhangshunping.github.io/js/insight.min.a343cd9a5a7698336b28ef3a7c16a3a1b1d2d5fb17dc8ed04022bbe08cc5459073a15bdafa3a8a58cdd56080784bdd69fa70b1ae8597565c799c57ed00f0e120.js" defer></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js"></script>
<script>
    tocbot.init({
        
        tocSelector: '.js-toc',
        
        contentSelector: '.js-toc-content',
        
        headingSelector: 'h1, h2, h3',
        
        hasInnerContainers: true,
    });
</script>


  </body>
</html>
