{"categories":[{"title":"Gin","uri":"https://zhangshunping.github.io/categories/gin/"},{"title":"k8s","uri":"https://zhangshunping.github.io/categories/k8s/"},{"title":"linux","uri":"https://zhangshunping.github.io/categories/linux/"},{"title":"个人开源小工具","uri":"https://zhangshunping.github.io/categories/%E4%B8%AA%E4%BA%BA%E5%BC%80%E6%BA%90%E5%B0%8F%E5%B7%A5%E5%85%B7/"},{"title":"云原生","uri":"https://zhangshunping.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"},{"title":"监控","uri":"https://zhangshunping.github.io/categories/%E7%9B%91%E6%8E%A7/"},{"title":"语言-golang","uri":"https://zhangshunping.github.io/categories/%E8%AF%AD%E8%A8%80-golang/"}],"posts":[{"content":"[toc]\ndynamic-Scheduler 背景 kubernetes调度策略默认根据node节点的request值（cpu和mem）进行调度，dynamic-Scheduler希望能够解决实际情况过程中遇到如下痛点\n  request设置太小，导致node节点上被分配太多的pod，面对流量高峰时，当前节点的资源使用率过高，导致一些pod 出现oom或者无法执行业务的情况。\n  request接近于limits,导致node节点上分配的pod数量有限，不能够最大容量的分配pod，而本身设置limits值的原因大多是基于高峰资源，而实际业务大多数情况并未处于高峰状态，所以会造成资源浪费。\n  个性化原因：\n  我们的业务模型创建的pod是自主性pod，虽然社区针对这样的问题有一些好用的开源的平衡组件descheduler，但不满足实际的问题，我们需要的是一个在调度的时候就可以根据资源消耗情况选择调度的组件，而descheduler是通过controller的方式对正在集群内的pod进行平衡，不满足我们目前的需求。\n  kubelet内存驱逐条件（memory.available）,是通过计算cgroups下资源换算得来的，我们的业务是频繁的创建pod环境，然后销毁，可能会有一些pod跑业务的gc出现问题，导致内存无法释放，而此时free -h看到的内存可使用率仍然ok，但实际上/sys/fs/cgroups/memory下的memory.usage_in_bytes的值已经接近整个内存总量了。根据公式\nmemory.available := node.status.capacity[memory]-node.stats.memory.workingSet  此时memory.available已经低于节点驱逐的available值，就会出现pod被驱逐。因此对于cgroups下memory.available的值也需要做一定的监控和调度策略，kubectl top 命令计算好像不太准确，因此使用pushGateWay的方式，收集节点的memory.available值到prometheus。根据kubelet计算memory.available脚本进行push。\n    解决思路 通过监控获取到各个k8s节点的使用率（cpu，mem等），当超过阈值后，给对应节点打上status=presure，根据k8s软亲和性策略，让pod尽量不调度到打上的presure标签的节点。\n  prometheus监控k8s集群的node资源使用率（因为是云原生背景，所以要自动发现弹性节点node，并对弹性节点进行监控）。需注意\n prometheus.yaml文件中采集node资源时，需要用如下的动态relabel机制，因为，client_golang采集Prometheus的metrics的数据为string，在dynamic-scheduler中使用ConvertResultDataType函数将string转换成[]string格式,这里的values为instance的值。 需要安装pushgateway，然后crontab的方式运行push.sh脚本，进行memory.available的采集   - job_name: '测试环境k8s资源节点监控' kubernetes_sd_configs: - role: node relabel_configs: - source_labels: [__meta_kubernetes_node_address_InternalIP] regex: '(.*)' replacement: '${1}:9100' target_label: __address__ - job_name: 'pushgateway' honor_labels: true static_configs: - targets: ['172.16.95.4:49091']    判断prometheus的返回得node使用率的metrics是否超过阈值，从而给k8s node节点打标签status=presure,根据k8s default的调度策略的软亲和preferredDuringSchedulingIgnoredDuringExecution策略，调度的时候尽量不调度到被打上标签status=presure的节点及当前资源紧张的节点。\ntemplate: metadata: labels: run: nginx spec: affinity: nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: - preference: matchExpressions: - key: status operator: NotIn values: - presure weight: 20    考虑到apiserver的压力问题，使用client—go 原生informer机制，减少对apiserver的压力。\n  promethues和dynamic-Scheduler 挂了情况，也不能影响到实际业务，因为使用的软亲和的方式，所以最终一定会有node被调度\n  使用方式 ./dynamic-sheduler --help -cmem float kubelet驱逐memory.availabele的阈值 (-cmem 2040) (default 2040) -cpu float 节点过去一分钟使用率阈值 (-cpu 10) (default 60) -kubeconfig string 链接k8s kubeconfig的绝对路径 (default \u0026quot;C:\\\\Users\\\\39295\\\\go\\\\src\\\\config\u0026quot;) -mem float 节点内存使用率阈值 (-mem 10) (default 80) -prom string prometheus链接地址(-prom http://121.40.XX.XX:49090) (default \u0026quot;http://121.40.XX.XX:49090\u0026quot;) -promjob string promtheus采集的node节点job名称(-promjob 测试环境k8s资源节点监控) (default \u0026quot;测试环境k8s资源节点监控\u0026quot;) -s int 每次抓取prometheus metrics间隔（-s 10) (default 10) -webaddr string 启动服务端口地址(-webaddr :9000) (default \u0026quot;:9000\u0026quot;) exit status 2   健康检测  curl ip:port/status   查询多少个节点打上了type=presure标签（返回json)  curl ip:port/nodes  ","id":0,"section":"posts","summary":"[toc] dynamic-Scheduler 背景 kubernetes调度策略默认根据node节点的request值（cpu和mem）进行调度，dynamic-Scheduler希望","tags":["Golang","kubernetes"],"title":"开源小工具- Dynamic Scheduler","uri":"https://zhangshunping.github.io/2020/09/dynamic-scheduler/","year":"2020"},{"content":"[toc]\n 监控的目的 在《SRE: Google运维解密》一书中指出，监控系统需要能够有效的支持白盒监控和黑盒监控。通过白盒能够了解其内部的实际运行状态，通过对监控指标的观察能够预判可能出现的问题，从而对潜在的不确定因素进行优化。而黑盒监控，常见的如HTTP探针，TCP探针等，可以在系统或者服务在发生故障时能够快速通知相关的人员进行处理。通过建立完善的监控体系，从而达到以下目的：\n 长期趋势分析：通过对监控样本数据的持续收集和统计，对监控指标进行长期趋势分析。例如，通过对磁盘空间增长率的判断，我们可以提前预测在未来什么时间节点上需要对资源进行扩容。 对照分析：两个版本的系统运行资源使用情况的差异如何？在不同容量情况下系统的并发和负载变化如何？通过监控能够方便的对系统进行跟踪和比较。 告警：当系统出现或者即将出现故障时，监控系统需要迅速反应并通知管理员，从而能够对问题进行快速的处理或者提前预防问题的发生，避免出现对业务的影响。 故障分析与定位：当问题发生后，需要对问题进行调查和处理。通过对不同监控监控以及历史数据的分析，能够找到并解决根源问题。 数据可视化：通过可视化仪表盘能够直接获取系统的运行状态、资源使用情况、以及服务运行状态等直观的信息。   Promql 什么是时间序列 通过Node Exporter暴露的HTTP服务，Prometheus可以采集到当前主机所有监控指标的样本数据。例如：\n# HELP node_cpu Seconds the cpus spent in each mode. # TYPE node_cpu counter node_cpu{cpu=\u0026quot;cpu0\u0026quot;,mode=\u0026quot;idle\u0026quot;} 362812.7890625 # HELP node_load1 1m load average. # TYPE node_load1 gauge node_load1 3.0703125  其中非#开头的每一行表示当前Node Exporter采集到的一个监控样本：node_cpu和node_load1表明了当前指标的名称、大括号中的标签则反映了当前样本的一些特征和维度、浮点数则是该监控样本的具体值。\n样本 Prometheus将所有的样本数据以时间序列(time-series)的方式存放在内存里，并定时保存到硬盘上。\ntime-series是按照时间戳和值的序列顺序存放的，我们称之为向量(vector). 每条time-series通过指标名称(metrics name)和一组标签集(labelset)命名。如下所示，可以将time-series理解为一个以时间为Y轴的数字矩阵：\n ^ │ . . . . . . . . . . . . . . . . . . . node_cpu{cpu=\u0026quot;cpu0\u0026quot;,mode=\u0026quot;idle\u0026quot;} │ . . . . . . . . . . . . . . . . . . . node_cpu{cpu=\u0026quot;cpu0\u0026quot;,mode=\u0026quot;system\u0026quot;} │ . . . . . . . . . . . . . . . . . . node_load1{} │ . . . . . . . . . . . . . . . . . . v \u0026lt;------------------ 时间 ----------------\u0026gt;  在time-series中的每一个点称为一个样本（sample），样本由以下三部分组成：\n 指标(metric)：metric name和描述当前样本特征的labelsets; 时间戳(timestamp)：一个精确到毫秒的时间戳; 样本值(value)： 一个float64的浮点型数据表示当前样本的值。  \u0026lt;--------------- metric ---------------------\u0026gt;\u0026lt;-timestamp -\u0026gt;\u0026lt;-value-\u0026gt; http_request_total{status=\u0026quot;200\u0026quot;, method=\u0026quot;GET\u0026quot;}@1434417560938 =\u0026gt; 94355 http_request_total{status=\u0026quot;200\u0026quot;, method=\u0026quot;GET\u0026quot;}@1434417561287 =\u0026gt; 94334 http_request_total{status=\u0026quot;404\u0026quot;, method=\u0026quot;GET\u0026quot;}@1434417560938 =\u0026gt; 38473 http_request_total{status=\u0026quot;404\u0026quot;, method=\u0026quot;GET\u0026quot;}@1434417561287 =\u0026gt; 38544 http_request_total{status=\u0026quot;200\u0026quot;, method=\u0026quot;POST\u0026quot;}@1434417560938 =\u0026gt; 4748 http_request_total{status=\u0026quot;200\u0026quot;, method=\u0026quot;POST\u0026quot;}@1434417561287 =\u0026gt; 4785  指标(Metric) 在形式上，所有的指标(Metric)都通过如下格式标示：\n\u0026lt;metric name\u0026gt;{\u0026lt;label name\u0026gt;=\u0026lt;label value\u0026gt;, ...}  指标的名称(metric name)可以反映被监控样本的含义（比如，http_request_total - 表示当前系统接收到的HTTP请求总量）。指标名称只能由ASCII字符、数字、下划线以及冒号组成并必须符合正则表达式[a-zA-Z_:][a-zA-Z0-9_:]*。\n标签(label)反映了当前样本的特征维度，通过这些维度Prometheus可以对样本数据进行过滤，聚合等。标签的名称只能由ASCII字符、数字以及下划线组成并满足正则表达式[a-zA-Z_][a-zA-Z0-9_]*。\n其中以__作为前缀的标签，是系统保留的关键字，只能在系统内部使用。标签的值则可以包含任何Unicode编码的字符。在Prometheus的底层实现中指标名称实际上是以__name__=的形式保存在数据库中的，因此以下两种方式均表示的同一条time-series：\napi_http_requests_total{method=\u0026quot;POST\u0026quot;, handler=\u0026quot;/messages\u0026quot;}  等同于：\n{__name__=\u0026quot;api_http_requests_total\u0026quot;，method=\u0026quot;POST\u0026quot;, handler=\u0026quot;/messages\u0026quot;}  在Prometheus源码中也可以找到指标(Metric)对应的数据结构，如下所示：\ntype Metric LabelSet type LabelSet map[LabelName]LabelValue type LabelName string type LabelValue string  数据类型 Counter:只增不减的计数器  一般在定义Counter类型指标的名称时推荐使用_total作为后缀,如http_requests_total，node_cpu都是Counter类型的监控指标  Gauge: 可增可减的仪表盘  Gauge类型的指标侧重于反应系统的当前状态。因此这类指标的样本数据可增可减。常见指标如：node_memory_MemFree（主机当前空闲的内容大小）、node_memory_MemAvailable（可用内存大小）都是Gauge类型的监控指标。通过Gauge指标，用户可以直接查看系统的当前状态node_memory_MemFree  Summary \u0026amp;\u0026amp; Histogram   适用于一般使用于解决长尾问题\n  Histogram 统计数据的分部情况。比如最小值，最大值，中间值，中位数，75百分位，90百分位，95/98/99/99.9百分位的值（percentlies）\n这是一种特殊的 metrics 数据类型，代表的是一种 近似的百分比估算值\n  Summary和Histogram十分相似，常用于跟踪事件发生的规模，例如：请求耗时、响应大小。同样提供 count 和 sum 全部值的功能。例如：count=7次，sum=7次的值求值。 它提供一个quantiles的功能，可以按%比划分跟踪的结果。例如：quantile取值0.95，表示取采样值里面的95%数据。  **同时对于Histogram的指标，我们还可以通过histogram_quantile()函数计算出其值的分位数。不同在于Histogram通过histogram_quantile函数是在服务器端计算的分位数。 而Sumamry的分位数则是直接在客户端计算完成。因此对于分位数的计算而言，Summary在通过PromQL进行查询时有更好的性能表现，而Histogram则会消耗更多的资源。反之对于客户端而言Histogram消耗的资源更少。在选择这两种方式时用户应该按照自己的实际场景进行选择。**  Promql查询 查询时间序列  精确匹配：== != 正则匹配 =~ !~  http_requests_total{environment=~\u0026quot;staging|testing|development\u0026quot;,method!=\u0026quot;GET\u0026quot;}\n范围查询 我们通过``http_requests_total`查询，返回值中只会包含该时间序列中的最新的一个样本值，这样的返回结果我们称为**__瞬时向量__**,而相应的这样的表达式称之为__瞬时向量表达式__.\n如果想去查询一段时间内的样本数据时，我们则需要__区间向量表达式__http_requests_total{}[5m],区间向量单位：\n s - 秒 m - 分钟 h - 小时 d - 天 w - 周 y - 年  时间位移查询 关键字 offset\nhttp_request_total{} offset 5m //5分钟前的瞬时向量 http_request_total{}[1d] offset 1d //昨天一天内的区间向量  聚合操作 Prometheus还提供了下列内置的聚合操作符，这些操作符作用域瞬时向量。可以将瞬时表达式返回的样本数据进行聚合，形成一个新的时间序列。\n\u0026lt;aggr-op\u0026gt;([parameter,] \u0026lt;vector expression\u0026gt;) [without|by (\u0026lt;label list\u0026gt;)]   sum (求和) min (最小值) max (最大值) avg (平均值) stddev (标准差) stdvar (标准方差) count (计数) count_values (对value进行计数) bottomk (后n条时序) topk (前n条时序) quantile (分位数)  例子：\n##计算k8s节点cpu资源 avg (irate(node_cpu_seconds_total[15m]) )by (instance) ##第一步： irate(node_cpu_secondes_total[15m] )获取瞬时向量 ### 第二步：by instance 及把所有instance相同的metric 放在一起取平均值 avg (irate(node_cpu_seconds_total[15m]) )by (instance)  ","id":1,"section":"posts","summary":"[toc] 监控的目的 在《SRE: Google运维解密》一书中指出，监控系统需要能够有效的支持白盒监控和黑盒监控。通过白盒能够了解其内部的实际运行状态","tags":["监控","prometheus"],"title":"Prometheus（一）","uri":"https://zhangshunping.github.io/2020/08/prometheus1/","year":"2020"},{"content":"[TOC]\n Export_execl Purpose Export_execl is my a little tool that Perform export execl tasks and send it as attachment to the designated person’s mailbox according to the needs。Only suport export execl from mysql.\nHow to use it Develop Language python2 , Golang \u0026gt;= 1.14\nstep1 . Compile goEmail by go mod cd sendEmailByGo go mod init sendEmailByGo go build -o goEmail -i main.go cp goEmail /usr/local/bin/ // 拷贝eamil stmp服务配置文件 mkdir -p /root/.email/ cp goEmailExample.json /root/.email/goEmail.json   goEmial help  [root@taliyun-k8s-master01 Export_execl]# goEmail -h Usage of goEmail: -a string 附件路径名字 -b string 邮件内容 (default \u0026quot;弹性伸缩web健康检查失败,健康码是：\u0026quot;) -c string goEmail.json文件存放路径 (default \u0026quot;/root/.email/\u0026quot;) -h\t帮助说明 -s string 邮件主题 (default \u0026quot;弹性伸缩web健康检测失败!\u0026quot;) [root@taliyun-k8s-master01 Export_execl]#  step2. Configuration cat config.ini\nScreenshots  When you complete the Step1 and Step2 configuration, and then you can execute command python export_execl_from_mysql.py  `   Recived an email that has Execl Attachment.  ","id":2,"section":"posts","summary":"[TOC] Export_execl Purpose Export_execl is my a little tool that Perform export execl tasks and send it as attachment to the designated person’s mailbox according to the needs。Only suport export execl from mysql. How to use it Develop Language python2 , Golang \u0026gt;= 1.14 step1 . Compile goEmail by go mod cd sendEmailByGo go","tags":["Golang","Python"],"title":"开源小工具- Export-execl","uri":"https://zhangshunping.github.io/2020/07/export-execl/","year":"2020"},{"content":"[TOC]\nobjectss  objectss 是为大数据大并发迁移到对象存储上而设计开源小项目。\nPurpose  背景： 公司战略问题，需要从阿里云迁移到华为云；使用的git服务器，有10T的存储容量，希望高并发的执行迁移任务，同时将一些不经常使用的git仓库存储在云对象存储上，等到要用时候去上面拉取。 选择：使用golang高并发的执行迁移任务,对接云存储的结构，进行数据传输。  Model 基于生产者多个消费者模型   生产者\n 通过查询sql中记录的gitpath路径，放入到带缓冲区的管道中    消费者\n 根据参数-s 指定的int值(默认10) 启用的消费者go程执行 obs/oss 迁移任务 如果迁移成功，则修改数据中的flag oss=1证明已经迁移到cloud 对象存储上了，如果迁移命令失败 则oss 仍然为0    Help $ go run main.go -h upload files to cloud oss Usage: objectss [command] Available Commands: help Help about any command obs huawei cloud obs oss aliyun object oss Flags: -c, --ChannelCap int channle cap (-c 10) (default 10) -l, --ObjectStorgeLink string oss/obs link (-o oss://educoder.tmp ) (default \u0026quot;oss://educoder.tmp\u0026quot;) --config string config file (default is $HOME/.objectss.yaml) -s, --consusmerNum int Run the number of comsumer goroutines (-s 100) (default 100) -h, --help help for objectss -n, --sqlLimits int sql limit nums (-n 1000) (default 1000) --sqlcon string connect sql (default is $HOME/.objectss.yaml) (default \u0026quot;root:123456789@tcp(127.0 .0.1:3306)/gitlab\u0026quot;) -d, --sqldays int select data from mysql 15 days ago (-d -15) (default -15) -t, --toggle Help message for toggle Use \u0026quot;objectss [command] --help\u0026quot; for more information about a command.  需补充 oss和obs存储迁移的 命令嵌入\n","id":3,"section":"posts","summary":"[TOC] objectss objectss 是为大数据大并发迁移到对象存储上而设计开源小项目。 Purpose 背景： 公司战略问题，需要从阿里云迁移到华为云；使用的git服务器，有10T的存储容","tags":["Golang"],"title":"开源小工具-objectss","uri":"https://zhangshunping.github.io/2020/07/objectss/","year":"2020"},{"content":"我的Gin 项目结构 ├── Config //处理配置文件代码 │ └── cofig1.go ├── Controller //控制层 │ ├── controllerHanlder.go │ ├── DbHandler.go │ └── StaticHandler │ ├── HelloWorld.go │ ├── Info.go │ └── PageNotFound.go ├── go.mod ├── go.sum ├── main.go ├── Middlerwar\t//中间件 │ └── m1.go ├── README.md ├── README.mdls ├── Router\t// 路由 │ ├── apiRouter.go │ ├── SysRouter.go │ └── init_router.go ├── Service\t// 业务逻辑 │ └── service1.go ├── Utils\t// 工具 ├── Model\t// 数据库  定义Router套路  router目录  ├── Router\t// 路由 │ ├── apiRouter.go │ ├── SysRouter.go │ └── init_router.go    init_router.go为init初始化目录\nimport ( \u0026quot;Edu-DevopsWeb/Controller/StaticHandler\u0026quot; \u0026quot;github.com/gin-gonic/gin\u0026quot; ) func InitDefaultRouter(m ...gin.HandlerFunc){ r:=gin.Default() //1.是否使用https //if config2.ApplicationConfig.IsHttps { //\tr.Use(handler.TlsHandler()) //} //2.是否使用中间件 // middleware.InitMiddleware(r) // the jwt middleware //authMiddleware, err := middleware.AuthInit() //tools.HasError(err, \u0026quot;JWT Init Error\u0026quot;, 500) //3、注册系统路由 InitSysRouter(r, authMiddleware) //InitSysRouter(r,authMiddlerware) //4. 注册业务路由 //\tInitExamplesRouter(r, authMiddleware) // Not Router 提示 r.NoRoute(StaticHandler.NotFound) r.Run(\u0026quot;:80\u0026quot;) }    分别定义 base路由和业务路由. 业务路由里又可以定义版本路由，认证路由，不需要认证的路由，这样的话，在以后的CURD过程中，就可以把需要版本控制，权限控制等路由添加到自定的方法中去。\n// 1.顶一个InitSysRouter 初始化业务路由，基本路由，需要check得路由等等 func InitSysRouter( r *gin.Engine){ g:=r.Group(\u0026quot;\u0026quot;) // init base router InitBaseRouter(g) // init 业务router(example) V1(g) // 无需认证 } // 2. 定义基本路由 func InitBaseRouter(g *gin.RouterGroup) { g.GET(\u0026quot;/\u0026quot;,StaticHandler.HelloWorld) g.GET(\u0026quot;/info\u0026quot;,StaticHandler.InfoHandlerFunc) } //3. 定义业务版本管理, func V1(g *gin.RouterGroup,authMiddleware ...gin.HandlerFunc){ g=g.Group(\u0026quot;/v1\u0026quot;) // 注册业务 { InitDbrouter(g,) } } //4.定义业务路由方法 func InitDbrouter(g *gin.RouterGroup, handlerFunc ...gin.HandlerFunc) { g.GET(\u0026quot;/db/\u0026quot;,Controller.DbGetHanderFunc) }    ","id":4,"section":"posts","summary":"我的Gin 项目结构 ├── Config //处理配置文件代码 │ └── cofig1.go ├── Controller //控制层 │ ├── controllerHanlder.go │ ├── DbHandler.go │ └── StaticHandler │ ├── HelloWorld.go │ ├── Info.go │ └── PageNotFound.go ├──","tags":["golang","Gin"],"title":"Gin_Router套路","uri":"https://zhangshunping.github.io/2020/07/gin_router/","year":"2020"},{"content":"[TOC]\n 背景 日常工作发现用kubectl 管理k8s集群虽然方便，但是针对某一些资源的CURD不是很好。 Kubect-addons 实对kubectl 命令的一个补充。使用到的包有 cobra ,go-client , color 。\n使用方法： [root@taliyun-k8s-master01 kubectl-addons]# ./kubectl-addons get nodeanno --help get node Annotation Usage: kubectl-addons get nodeanno [flags] Examples: 1.kubect-addons get nodeanno -a \u0026quot;CA\u0026quot; --\u0026gt; to get ClusterAutoSacler node that not to clam down 2. kubectl-addons get nodeanno -a \u0026quot;All\u0026quot; --\u0026gt; to get all Node Annotation 3. kubectl-addons get nodeanno -a '{\u0026quot;flannel.alpha.coreos.com/backend-type\u0026quot;:\u0026quot;vxlan\u0026quot;}' --\u0026gt; to list given Annotation Node 4. kubectl-addons get nodeanno -a '{\u0026quot;cluster-autoscaler.kubernetes.io/scale-down-disabled\u0026quot;:\u0026quot;true\u0026quot;}' -k C:/Users/39295/kube/config Flags: -a, --annotation string get nodeanno -a '{\u0026quot;flannel.alpha.coreos.com/backend-type\u0026quot;:\u0026quot;vxlan\u0026quot;}' ,to list gien node -h, --help help for nodeanno Global Flags: --config string config file (default is $HOME/.kubectl-addons.yaml) -k, --kubeconfig string -k C:/Users/39295/kube/config (default \u0026quot;/root/.kube/config\u0026quot;) -n, --namespace string -n default (default \u0026quot;default\u0026quot;) -l, --nodeslector string -l type=others --viper use Viper for configuration (default true)  截图  1.get cluster-auto-scaler node that not be scaled down .   2、get all node\u0026rsquo;s annotation in k8s cluster   get some specify annotation by user  ","id":5,"section":"posts","summary":"[TOC] 背景 日常工作发现用kubectl 管理k8s集群虽然方便，但是针对某一些资源的CURD不是很好。 Kubect-addons 实对kubectl 命令的一个补充。使用到的","tags":["Golang"],"title":"开源小工具- Kubectl Addons","uri":"https://zhangshunping.github.io/2020/07/kubectl-addons/","year":"2020"},{"content":"[TOC]\njson渲染 func main() { r := gin.Default() // 1、map渲染，gin.H{} r.GET(\u0026quot;/map_json\u0026quot;, func(c *gin.Context) { c.JSON(200, gin.H{ \u0026quot;message\u0026quot;: \u0026quot;map_json\u0026quot;, }) }) //2、 结构体渲染， r.GET(\u0026quot;/other_json\u0026quot;, func(c *gin.Context) { c.JSON(http.StatusOK,Other_json{Messag: \u0026quot;otherJson\u0026quot;}) }) r.Run() // listen and serve on 0.0.0.0:8080 (for windows \u0026quot;localhost:8080\u0026quot;) } type Other_json struct{ // `json:\u0026quot;name\u0026quot;` 表示用json包来处理的时候，字段名字为name Messag string `json:\u0026quot;name\u0026quot;` }  获取参数 Query 参数  C.GetQuery() and c.DefaultQuery()  r.GET(\u0026quot;/query\u0026quot;, func(c *gin.Context) { // 1、 c.DefaultQuery() value:=c.DefaultQuery(\u0026quot;hello\u0026quot;,\u0026quot;not_hello\u0026quot;) // 2、 c.GetQuery() value,ok:=c.GetQuery(\u0026quot;hello\u0026quot;) if !ok{ value=\u0026quot;not_hello\u0026quot; } c.JSON(http.StatusOK,gin.H{ \u0026quot;Msg\u0026quot;:value, }) })  PostForm 参数  c.DefaultPostForm() and c.GetPostForm()  r.Post(\u0026quot;/query\u0026quot;, func(c *gin.Context) { // 1、 c.DefaultQuery() value:=c.DefaultPostForm(\u0026quot;hello\u0026quot;,\u0026quot;not_hello\u0026quot;) // 2、 c.GetQuery() value,ok:=c.GetPostForm(\u0026quot;hello\u0026quot;) if !ok{ value=\u0026quot;not_hello\u0026quot; } c.JSON(http.StatusOK,gin.H{ \u0026quot;Msg\u0026quot;:value, }) })  Uri 参数 r.GET(\u0026quot;/api/v1/:year/:month\u0026quot; , func(c *gin.Context) { year:=c.Param(\u0026quot;year\u0026quot;) month:=c.Param(\u0026quot;month\u0026quot;) c.JSON(http.StatusOK,gin.H{ \u0026quot;year\u0026quot;:year, \u0026quot;month\u0026quot;:month, }) }) // 浏览器输入 ：http://127.0.0.1:8080/api/v1/2020/07 // 显示结果为 {\u0026quot;month\u0026quot;:\u0026quot;07\u0026quot;,\u0026quot;year\u0026quot;:\u0026quot;2020\u0026quot;}  参数绑定 基于请求的Content-Type识别请求数据类型并利用反射机制自动提取请求中QueryString、form表单、JSON、XML等参数到结构体中。\ntype Login struct { User string `form:\u0026quot;user\u0026quot; json:\u0026quot;user\u0026quot; xml:\u0026quot;user\u0026quot; ` Password string `form:\u0026quot;password\u0026quot; json:\u0026quot;password\u0026quot; xml:\u0026quot;password\u0026quot; ` } func main() { router := gin.Default() // Get query router.GET(\u0026quot;/login\u0026quot;, LoginHandler) // Get json router.GET(\u0026quot;/loginJ\u0026quot;, LoginHandlerJ) // Post query Form router.POST(\u0026quot;/loginF\u0026quot;, LoginHandlerF) router.Run(\u0026quot;:8080\u0026quot;) // listen and serve on 0.0.0.0:8080 (for windows \u0026quot;localhost:8080\u0026quot;) } // query bind //Get--\u0026gt; 127.0.0.1:8080/login?user2=apple\u0026amp;password3=apple1 func LoginHandler(c *gin.Context) { var login Login //if err:=c.ShouldBind(\u0026amp;login);err!=nil{ if err := c.ShouldBindQuery(\u0026amp;login); err != nil { c.JSON(http.StatusBadRequest, err.Error()) return } c.JSON(http.StatusOK, login) } // json bind // 传递 json{ \u0026quot;user\u0026quot;:\u0026quot;123\u0026quot;, \u0026quot;password\u0026quot;:\u0026quot;aple\u0026quot; } func LoginHandlerJ(c *gin.Context) { var login Login if err := c.ShouldBindJSON(\u0026amp;login); err != nil { c.JSON(http.StatusBadRequest, err.Error()) return } c.JSON(http.StatusOK, login) } //Form bind // Post --\u0026gt; 127.0.0.1:8080/loginF?user=apple\u0026amp;password=appple1 func LoginHandlerF(c *gin.Context) { var login Login if err := c.ShouldBindQuery(\u0026amp;login); err != nil { c.JSON(http.StatusBadRequest, err.Error()) return } c.JSON(http.StatusOK, login) }  文件上传  前端Form表单  \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;zh-CN\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;上传文件示例\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026quot;/upload\u0026quot; method=\u0026quot;post\u0026quot; enctype=\u0026quot;multipart/form-data\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;file\u0026quot; name=\u0026quot;f1\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;submit\u0026quot; value=\u0026quot;上传\u0026quot;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   单文件上传  func main() { // 处理multipart forms提交文件时默认的内存限制是32 MiB // 可以通过下面的方式修改 // router.MaxMultipartMemory = 8 \u0026lt;\u0026lt; 20 // 8 MiB\trouter := gin.Default() router.LoadHTMLFiles(\u0026quot;html/upload.html\u0026quot;) router.GET(\u0026quot;/index\u0026quot;, func(c *gin.Context) { c.HTML(http.StatusOK,\u0026quot;upload.html\u0026quot;,nil) }) router.POST(\u0026quot;/upload\u0026quot;,UploadHanderFunc) router.Run(\u0026quot;:8080\u0026quot;) // listen and serve on 0.0.0.0:8080 (for windows \u0026quot;localhost:8080\u0026quot;) } // file,err:=c.FORMFILE(f) //c.SaveUpLoadFile(file,path) func UploadHanderFunc(c *gin.Context){ if file,err:=c.FormFile(\u0026quot;f1\u0026quot;);err !=nil{ c.JSON(http.StatusInternalServerError,err.Error()) return }else{ filePath:=path.Join(\u0026quot;./upload/\u0026quot;,file.Filename) c.SaveUploadedFile(file,filePath) c.JSON(http.StatusOK,gin.H{ \u0026quot;status\u0026quot;:\u0026quot;ok\u0026quot;, }) } }   多个文件  func main() { router := gin.Default() // 处理multipart forms提交文件时默认的内存限制是32 MiB // 可以通过下面的方式修改 // router.MaxMultipartMemory = 8 \u0026lt;\u0026lt; 20 // 8 MiB router.POST(\u0026quot;/upload\u0026quot;, func(c *gin.Context) { // Multipart form form, _ := c.MultipartForm() files := form.File[\u0026quot;file\u0026quot;] for index, file := range files { log.Println(file.Filename) dst := fmt.Sprintf(\u0026quot;C:/tmp/%s_%d\u0026quot;, file.Filename, index) // 上传文件到指定的目录 c.SaveUploadedFile(file, dst) } c.JSON(http.StatusOK, gin.H{ \u0026quot;message\u0026quot;: fmt.Sprintf(\u0026quot;%d files uploaded!\u0026quot;, len(files)), }) }) router.Run() }  路由 重定向  http重定向  router := gin.Default() //1、 HTTP重定向，通过C.Redirect router.GET(\u0026quot;/version1\u0026quot;, func(c *gin.Context) { //跳转到baidu //c.Redirect(http.StatusMovedPermanently,\u0026quot;https://www.baidu.com\u0026quot;) //跳转到v2 c.Redirect(http.StatusMovedPermanently,\u0026quot;v2\u0026quot;) }) router.GET(\u0026quot;/v2\u0026quot;, func(c *gin.Context) { c.JSON(http.StatusPermanentRedirect,gin.H{ \u0026quot;status\u0026quot;:\u0026quot;ok\u0026quot;, \u0026quot;version\u0026quot;:\u0026quot;v2\u0026quot;, }) })   路由重定向  //2、 路由重定向 (跳转到c2，但是url还是127.0.0.1/v1 router.GET(\u0026quot;/v1\u0026quot;, func(c *gin.Context) { c.Request.URL.Path=\u0026quot;/v2\u0026quot; router.HandleContext(c) }) router.GET(\u0026quot;/v2\u0026quot;, func(c *gin.Context) { c.JSON(http.StatusPermanentRedirect,gin.H{ \u0026quot;status\u0026quot;:\u0026quot;ok\u0026quot;, \u0026quot;version\u0026quot;:\u0026quot;v2\u0026quot;, }) })  路由组 func main() { router := gin.Default() // 定义路由组 以/www为开头的 IndexGroup := router.Group(\u0026quot;/www\u0026quot;) { // 通过any() switch定义restful , // 访问的地址为uri为 /www/list/ IndexGroup.Any(\u0026quot;/list\u0026quot;, func(c *gin.Context) { switch c.Request.Method { // 查 case http.MethodGet: c.JSON(http.StatusOK, gin.H{ \u0026quot;status\u0026quot;: \u0026quot;ok\u0026quot;, \u0026quot;Method\u0026quot;: http.MethodGet, }) // 增 case http.MethodPost: c.JSON(http.StatusOK, gin.H{ \u0026quot;status\u0026quot;: \u0026quot;ok\u0026quot;, \u0026quot;Method\u0026quot;: http.MethodPost, }) //改 case http.MethodPut: c.JSON(http.StatusOK, gin.H{ \u0026quot;status\u0026quot;: \u0026quot;ok\u0026quot;, \u0026quot;Method\u0026quot;: http.MethodPut, }) // 删 case http.MethodDelete: c.JSON(http.StatusOK, gin.H{ \u0026quot;status\u0026quot;: \u0026quot;ok\u0026quot;, \u0026quot;Method\u0026quot;: http.MethodDelete, }) } }) } // No route，定义无路由规则 router.NoRoute(func(c *gin.Context) { c.JSON(http.StatusNotFound, gin.H{ \u0026quot;Err\u0026quot;: \u0026quot;Page NOt Found!\u0026quot;, }) }) router.Run(\u0026quot;:80\u0026quot;) // listen and serve on 0.0.0.0:8080 (for windows \u0026quot;localhost:8080\u0026quot;) }   路由组嵌套  router := gin.Default() // 定义路由组 IndexGroup := router.Group(\u0026quot;/www\u0026quot;) IndexGroup.Any(\u0026quot;/list\u0026quot;, func(c *gin.Context) { switch c.Request.Method { // 查 case http.MethodGet: c.JSON(http.StatusOK, gin.H{ \u0026quot;status\u0026quot;: \u0026quot;ok\u0026quot;, \u0026quot;Method\u0026quot;: http.MethodGet, }) } }) // 嵌套 xx:=IndexGroup.Group(\u0026quot;ex\u0026quot;) // 访问地址为: http://127.0.0.1/www/ex/ xx.GET(\u0026quot;/\u0026quot;,xxHandelr)  中间件 允许框架的使用者在使用框架的时候，加入自己的一些定义的hook函数。（使用处理一些公共的资源），比如登陆登陆验证，权限认证，数据分页，记录日志，耗时统计等。\n自定义中间件 Gin中的中间件必须是一个gin.HandlerFunc类型\n// HandlerFunc defines the handler used by gin middleware as return value. type HandlerFunc func(*Context)  //一般用闭包定义中间件 func authUserM1(doChe bool) gin.HandlerFunc{ if doChe{ //1. 查询数据库 逻辑 //2. 校验成功逻辑 return func(c *gin.Context) {fmt.Println(\u0026quot;auth ok\u0026quot;)\t;c.Next()} } else { return func(c *gin.Context) {fmt.Println(\u0026quot;auth failed\u0026quot;)\t;c.Abort()} } }  中间件常见使用  处理流程  b--\u0026gt;m1Func ---\u0026gt;m2Func----\u0026gt;handerFunc b\u0026lt;--m1Func\u0026lt;----m2Func\u0026lt;----handerFunc //c.Next() 表示执行后面的Func //c.Abort() 表示终止后面的Func,直接按原路返回 router.Get(\u0026quot;/\u0026quot;,m1,m2,Handerfunc) func m1(c *gin.context){ fmt.Println(\u0026quot;m1 start\u0026quot;) c.Next() fmt.Println(\u0026quot;m1 end\u0026quot;) } func m2(c *gin.context){ fmt.Println(\u0026quot;m2 start\u0026quot;) c.Next() fmt.Println(\u0026quot;m2\u0026quot;) } // 输出结果为 \u0026quot;m1 start , m2 start , m2 end , m1 end\u0026quot;   伪代码模仿认证中间件  func main() { router:=gin.Default() //router.User() router.Use(authUserM1(true)) // 全局注册 //路由组注册 router.Use() Grouproute:=router.Group(\u0026quot;/\u0026quot;) Grouproute.Use(authUserM1(true)) //路由注册 router.GET(\u0026quot;/\u0026quot;,authUserM1(true), func(c *gin.Context) {c.JSON(http.StatusOK,gin.H{ \u0026quot;status\u0026quot;:\u0026quot;ok\u0026quot;, }) }) } func authUserM1(doChe bool) gin.HandlerFunc{ if doChe{ //1. 查询数据库 逻辑 //2. 校验成功逻辑 return func(c *gin.Context) {fmt.Println(\u0026quot;auth ok\u0026quot;)\t;c.Next()} } else { return func(c *gin.Context) {fmt.Println(\u0026quot;auth failed\u0026quot;)\t;c.Abort()} } }    注意事项\ngin默认中间件\ngin.Default()默认使用了Logger和Recovery中间件，其中：\n Logger中间件将日志写入gin.DefaultWriter，即使配置了GIN_MODE=release。 Recovery中间件会recover任何panic。如果有panic的话，会写入500响应码。  如果不想使用上面两个默认的中间件，可以使用gin.New()新建一个没有任何默认中间件的路由。\ngin中间件中使用goroutine\n当在中间件或handler中启动新的goroutine时，不能使用原始的上下文（c *gin.Context），必须使用其只读副本（c.Copy()）。\n  ","id":6,"section":"posts","summary":"[TOC] json渲染 func main() { r := gin.Default() // 1、map渲染，gin.H{} r.GET(\u0026quot;/map_json\u0026quot;, func(c *gin.Context) { c.JSON(200, gin.H{ \u0026quot;message\u0026quot;: \u0026quot;map_json\u0026quot;, }) }) //2、 结构体渲染， r.GET(\u0026quot;/other_json\u0026quot;, func(c *gin.Context) { c.JSON(http.StatusOK,Other_json{Messag: \u0026quot;otherJson\u0026quot;}) }) r.Run() // listen and serve on 0.0.0.0:8080 (for windows \u0026quot;localhost:8080\u0026quot;) } type Other_json struct{","tags":["golang","Gin"],"title":"Gin框架常见用法","uri":"https://zhangshunping.github.io/2020/07/gin_%E5%B8%B8%E8%A7%81%E7%94%A8%E6%B3%95/","year":"2020"},{"content":"[TOC]\nContext诞生背景 由于在Golang severs中，每个request都是在单个goroutine中完成，并且在单个goroutine（不妨称之为A）中也会有请求其他服务（启动另一个goroutine（称之为B）去完成）的场景，这就会涉及多个Goroutine之间的调用。如果某一时刻请求其他服务被取消或者超时，则作为深陷其中的当前goroutine B需要立即退出，然后系统才可回收B所占用的资源。 即一个request中通常包含多个goroutine，这些goroutine之间通常会有交互。\n那么，如何有效管理这些goroutine成为一个问题（主要是退出通知和元数据传递问题），Google的解决方法是Context机制，相互调用的goroutine之间通过传递context变量保持关联，这样在不用暴露各goroutine内部实现细节的前提下，有效地控制各goroutine的运行。\n如此一来，通过传递Context就可以追踪goroutine调用树，并在这些调用树之间传递通知和元数据。 虽然goroutine之间是平行的，没有继承关系，但是Context设计成是包含父子关系的，这样可以更好的描述goroutine调用之间的树型关系。\ncontext使用方式   Context是一个接口\ntype Context interface { Deadline() (deadline time.Time, ok bool) // 超时 Done() \u0026lt;-chan struct{} // 退出channel Err() error // err报错 Value(key interface{}) interface{} // context上下文value传递 }    context.go包自带的常用三种初始化方式\nctx,cancel:=context.WithCancel(context.Background()) ctx,cancel:=context.WithDeadline(context.Background(),time.Now().Add(time.Second*10)) ctx,cancle:=context.WithTimeout(context.Background(),time.Second*10) //返回是一个ctx Context，和一个cancel 函数体 //ctx有三种方式    context.withValue（）使用 trace_code的场景\nvar ( wg sync.WaitGroup ) // 按官方标准建立自己定义type type ContextTc struct { Traceid string } func main(){ traceid :=ContextTc{Traceid: \u0026quot;Trace_code\u0026quot;} // ctx 上下文初始化 ctx,cancle:=context.WithTimeout(context.Background(),time.Second*10) ctx=context.WithValue(ctx,traceid.Traceid,\u0026quot;1\u0026quot;) defer cancle() wg.Add(1) go worker(ctx,traceid.Traceid) wg.Wait() } func worker(ctx context.Context,traceid string){ select { //超市或者cacncle()时，等待ctx.Done() case \u0026lt;-ctx.Done(): fmt.Println(\u0026quot;context stop and exit\u0026quot;) return default: log.Printf(\u0026quot;Trace_code %s: working\u0026quot;,ctx.Value(traceid)) } defer wg.Done() }    ","id":7,"section":"posts","summary":"[TOC] Context诞生背景 由于在Golang severs中，每个request都是在单个goroutine中完成，并且在单个goroutine","tags":null,"title":"Golang-Context","uri":"https://zhangshunping.github.io/2020/06/golang-context/","year":"2020"},{"content":"[toc]\n定义 所谓闭包指的是内部函数引用外部函数变量或者自由变量返回一个函数，我们称作为闭包\nfunc outer(x int )func(int) int{ // golang一个函数体内只能用用一个函数体,因此使用匿名函数 return func(y int) int{ return x+y } } func main() { f:=outer(1) fmt.Println(f(100)) }  闭包场景一： for-range使用闭包 第一个示列： func main() { a:=[]string{\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;,\u0026quot;C\u0026quot;} for _,i:=range(a){ go func(){ fmt.Println(i) }() } time.Sleep(1*time.Second) }  输出结果居然不是：a,b,c 而是c，c，c 。\n第二个示列 func main() { a:=[]string{\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;,\u0026quot;C\u0026quot;} for _,i:=range(a){ go func(i string){ fmt.Println(i) }(i) } time.Sleep(1*time.Second) }  输出结果跟预期的一样。\n说明： 第一个示列，主进程跑的过快，go程里打印的i是值引用，因此打印的结果为i的最后一个值。而第二个示列中，直接传i值，因此打出的结果符合预期，当然我们可以针对示列一做如下修改,输出结果依然符合预期\nfunc main() { a:=[]string{\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;,\u0026quot;C\u0026quot;} for _,i:=range(a){ go func(){ fmt.Println(i) }() time.Sleep(1*time.Second) } time.Sleep(4*time.Second) }  闭包场景二：函数列表闭包 第三个示列 func funcslic() []func(){ s:=[]func(){} for i:=0; i\u0026lt;3;i++{ s=append(s, func() { fmt.Println(\u0026amp;i,i) }) } return s } func main(){ Fs:=funcslic() for _,k:=range(Fs){ k() } }  输出结果为：0x11056058 3 0x11056058 3 0x11056058 3\n第四个示列 func funcslic() []func(){ s:=[]func(){} for i:=0; i\u0026lt;3;i++{ x:=i s=append(s, func() { fmt.Println(\u0026amp;x,x) }) } return s } func main(){ Fs:=funcslic() for _,k:=range(Fs){ k() } }  输出结果为： 0x11056058 0 0x1105605c 1 0x11056070 2\n说明： 每次 append 操作仅将匿名函数放入到列表中，但并未执行，并且引用的变量都是 i，随着 i 的改变匿名函数中的 i 也在改变，所以当执行这些函数时，他们读取的都是环境变量 i 最后一次的值。解决的方法就是每次复制变量 i 然后传到匿名函数中(及为局部变量），让闭包的环境变量不相同。因此我们就可以用闭包来修改环境变量如下：\nvar a int =10 func main(){ go func(){ a=a+2 }() fmt.Println(a) } //怎么样，是不是觉得这段代码，经常使用。  闭包场景三：延迟调用defer 第五个示列 package main import \u0026quot;fmt\u0026quot; func main(){ var x,y int=1,2 defer func(i int){ fmt.Println(\u0026quot;defer\u0026quot;,i,y) }(x) x=100 y=100 fmt.Println(\u0026quot;main\u0026quot;,x,y) } //输出结果 $ go run main.go main 100 100 defer 1 100  闭包场景四：return, defer 第五个示列 不带命名的返回值\npackage main import \u0026quot;fmt\u0026quot; var i int func test() (int) { defer func(){ i++ fmt.Println(\u0026quot;defer1\u0026quot;,i) }() defer func(){ i++ fmt.Println(\u0026quot;defer2\u0026quot;,i) }() return i } func main() { fmt.Println(\u0026quot;test return\u0026quot;,test()) }  输出结果为：defer2 1 defer1 2 test return 0\n第六个示列 带命名的返回值\npackage main import \u0026quot;fmt\u0026quot; func test() (i int) { defer func(){ i++ fmt.Println(\u0026quot;defer1\u0026quot;,i) }() defer func(){ i++ fmt.Println(\u0026quot;defer2\u0026quot;,i) }() return i } func main() { fmt.Println(\u0026quot;test return\u0026quot;,test()) }  输出结果为：\n$ go run main.go defer2 1 defer1 2 test return 2\ndefer，return 说明： return 是一个并非原子操作，分别为赋值和返回值两步操作。return i 可以看作 j:=i 返回j\n不带命名的返回值： return 最先执行，此时i=0,j:=i，返回的值为j；defer2后入栈，先出i=i+1，defer1先进，后出i=1+1\n带命名的返回值：\nreturn 最先执行，此时i=0,j:=i，返回的是j；defer2后入栈，先出i=i+1，defer1先进，后出i=1+1 ，逻辑跟上面一样，但是命名的返回值是i，而不是j，所以结果是2\n总结： 闭包紧盯着外部变量; defer语句，优先入栈。\n","id":8,"section":"posts","summary":"[toc] 定义 所谓闭包指的是内部函数引用外部函数变量或者自由变量返回一个函数，我们称作为闭包 func outer(x int )func(int) int{ // golang一个函数体内只能用用一个函数体,","tags":["golang"],"title":"Golang-闭包场景总结","uri":"https://zhangshunping.github.io/2020/06/golang-%E9%97%AD%E5%8C%85%E5%9C%BA%E6%99%AF%E6%80%BB%E7%BB%93/","year":"2020"},{"content":"[TOC]\n需求背景 ​\t公司的2B业务落地后，应用服务因为一些突发状况出现不在线情况。\n  一些小型客户关注的是SAAS业务，不太关心运维体系，也没有充裕的资源建立一套运维系统。\n  开源组件建立本地版运维体系，较为烦躁。\n  希望能够建立一套健康检测系统，在服务出现问题是，能够到连接到指定的机器上执行HOOK命令；同时根据用户实际情况，建立通知系统。\n由于最近半年在golang方面的东西，因此用golang语言写了一个Healthy健康检测服务，取名为Healthy\n  介绍 Healthy是一个通过golang语言写的服务健康检测服务，再发现连续报错之后会通过ssh协议链接指定的主机上执行Hook指令。同时根据用户自定义的Email开关，实现邮件通知（故障报警，恢复通知，报警冷却）。\n软件架构 - Appservice 服务注册，检测，执行Hook - Sshconnect ssh模块 - Email 报警邮件  Hook操作函数： - 执行cmd命令 - 执行通知事件  安装教程 git clone https://gitee.com/zhangshunping123/Healthy.git go build -o healthy -i main.go chmod +x healthy mv healthy /usr/bin/  使用说明 mkdir -p ~/.health/ cp config.json ~/.health/ $ ./main.exe -h Usage of C:\\Users\\39295\\Desktop\\Healthy\\main.exe: -c string Configfile for service health detection (default \u0026quot;~/.health/config.json\u0026quot;) -e int Number of consecutive health test failures (default 10) -h help -i int Health check interval (default 2)  需要补充  hook interface化 多种 通知方式接入 视图友好  ","id":9,"section":"posts","summary":"[TOC] 需求背景 ​ 公司的2B业务落地后，应用服务因为一些突发状况出现不在线情况。 一些小型客户关注的是SAAS业务，不太关心运维体系，也没有充裕的资","tags":["Golang"],"title":"Healthy","uri":"https://zhangshunping.github.io/2020/06/%E5%B0%8F%E5%B7%A5%E5%85%B7-projecthealthy/","year":"2020"},{"content":"[TOC]\n channel，Deadlock死锁的本质 **主协程程阻塞，系统一直等待，导致系统死锁**  场景一： 主协程中使用channel // 1.1 无缓冲channel，读 ch1 := make(chan string) \u0026lt;- ch1 fmt.Println(\u0026quot;ok\u0026quot;) // 1.2 无缓冲channel，写 func main(){ ch1 := make(chan string) ch1 \u0026lt;- \u0026quot;ok\u0026quot; fmt.Println(\u0026quot;ok\u0026quot;) } ##说明： 是因为在同一个主协程中，无缓冲的channel 读和写都是阻塞的，导致系统等待超时，导致deadlock // 2.1 有缓冲读写 func main(){ ch1 := make(chan string,1) ch1 \u0026lt;- \u0026quot;ok\u0026quot; ch1 \u0026lt;- \u0026quot;ok2\u0026quot; fmt.Println(\u0026quot;ok\u0026quot;) } ## 说明： ch1为戴缓冲区1的channel ，写一个ok的时候，主协程不阻塞，写第二个ok2的时候，此时ch1可以看作无缓冲channel，及出现主协程阻塞，导致系统等待，从而deadlock ///修复 //2.1 go 程中使用channel取值 func main(){ ch1 := make(chan string) go func(){ fmt.Println(\u0026quot;ok\u0026quot;,\u0026lt;- ch1) }() ch1\u0026lt;-\u0026quot;ok\u0026quot; time.Sleep(time.Second*1) } //2.2 go程使用channel 赋值 func main(){ ch1 := make(chan string) go func(){ ch1\u0026lt;-\u0026quot;ok\u0026quot; }() fmt.Println(\u0026quot;get from go channle\u0026quot;,\u0026lt;-ch1) } //2.3 注意,如果2.2这样写又会死锁，因为\u0026lt;-ch1在阻塞，导致主协程系统等待 func main(){ ch1 := make(chan string) go func(){ ch1\u0026lt;-\u0026quot;ok\u0026quot; }() fmt.Println(\u0026quot;get from go channle\u0026quot;,\u0026lt;-ch1) fmt.Println(\u0026quot;get2 from go channle\u0026quot;,\u0026lt;-ch1) } //2.4 针对2.3的情况,go程close(ch1)，这样主协程及不会出现等待的情况 func main(){ ch1 := make(chan string) go func(){ ch1\u0026lt;-\u0026quot;ok\u0026quot; close(ch1) }() fmt.Println(\u0026quot;get from go channle\u0026quot;,\u0026lt;-ch1) fmt.Println(\u0026quot;get2 from go channle\u0026quot;,\u0026lt;-ch1) }  场景二：channel遍历导致的deadlock //3.1 range遍历 func main(){ chs := make(chan string, 2) chs \u0026lt;- \u0026quot;first\u0026quot; chs \u0026lt;- \u0026quot;second\u0026quot; for ch := range chs { fmt.Println(ch) } } // 3.2 range遍历修复deadlock func main(){ chs := make(chan string, 2) chs \u0026lt;- \u0026quot;first\u0026quot; chs \u0026lt;- \u0026quot;second\u0026quot; for i:=0;i\u0026lt;=len(chs);i++{ fmt.Println(\u0026lt;-chs) } } //3.3 修复range遍历deadlocak func main(){ chs := make(chan string, 2) chs \u0026lt;- \u0026quot;first\u0026quot; chs \u0026lt;- \u0026quot;second\u0026quot; close(chs) for ch := range chs { fmt.Println(ch) } }  场景三：生产者消费者模型Deadlock //4.1 deadlock func main(){ ch1:=make(chan interface{}) quit:=make(chan bool) // producer go func(){ for i:=0;i\u0026lt;=10;i++{ ch1\u0026lt;-i } }() // comsumer go func(){ for{ fmt.Println(\u0026quot;生产者生产为\u0026quot;,\u0026lt;-ch1) } quit\u0026lt;-true }() \u0026lt;-quit } //说明：是因为quit\u0026lt;-true一直被\u0026lt;-ch1阻塞了，导致了主协程的quit一直阻塞 //4.2改进 func main(){ ch1:=make(chan int) quit:=make(chan bool) // producer go func(){ for i:=0;i\u0026lt;=10;i++{ ch1\u0026lt;-i } }() // comsumer go func(){ for{ select { case num:=\u0026lt;-ch1: fmt.Println(\u0026quot;从管道获取的value是\u0026quot;,num) case \u0026lt;-time.After(3*time.Second): goto loop } } loop: fmt.Println(\u0026quot;loop\u0026quot; ) quit\u0026lt;-true }() \u0026lt;-quit }  ","id":10,"section":"posts","summary":"[TOC] channel，Deadlock死锁的本质 **主协程程阻塞，系统一直等待，导致系统死锁** 场景一： 主协程中使用channel // 1.1 无缓冲ch","tags":["golang-channel","golang"],"title":"Golang-Channel死锁场景总结","uri":"https://zhangshunping.github.io/2020/06/channel-%E6%AD%BB%E9%94%81%E5%9C%BA%E6%99%AF%E6%80%BB%E7%BB%93/","year":"2020"},{"content":"[ToC]\n目的 在实际的生产中能够熟练的使用awk ，sed ，grep等文本操作工具，对故障的快速定位，日志分析等有很大帮助，于是根据自己的实际的生产经验，总结一下awk的用法。\nawk 基本结构 awk 'BEGIN{ print \u0026quot;start\u0026quot; } pattern{ commands } END{ print \u0026quot;end\u0026quot; }' file  一个awk脚本通常由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块3部分组成，这三个部分是可选的。任意一个部分都可以不出现在脚本中，脚本通常是被单引号或双引号中，例如：\nawk 'BEGIN{ i=0 } { i++ } END{ print i }' filename ##上面的方法跟cat filename|wc -l 的效果一样  awk 常见内置变量 $n 当前记录的第n个字段，比如n为1表示第一个字段，n为2表示第二个字段。 $0 这个变量包含执行过程中当前行的文本内容。 [A] FILENAME 当前输入文件的名。 [A] FS 字段分隔符（默认是任何空格）。 [A] NF 表示字段数，在执行过程中对应于当前的字段数。 [A] NR 表示记录数，在执行过程中对应于当前的行号。 [A] OFMT 数字的输出格式（默认值是%.6g）。 [A] OFS 输出字段分隔符（默认值是一个空格）。 [A] ORS 输出记录分隔符（默认值是一个换行符）。 [A] RS 记录分隔符（默认是一个换行符）。  NR和FNR   NR：表示awk开始执行程序后所读取的数据行数。\nFNR：awk当前读取的记录数，其变量值小于等于NR（比如当读取第二个文件时，FNR是从0开始重新计数，而NR不会）。\n    NR==FNR：用于在读取两个或两个以上的文件时，判断是不是在读取第一个文件\n[root@k8s-master01 tmp]# cat a 张三|000001 李四|000002 [root@k8s-master01 tmp]# cat b 000001|10 000001|20 000002|30 000002|15 [root@k8s-master01 tmp]# awk -F '|' 'NR==FNR{a[$2]=$0;next}{print a[$1]\u0026quot;|\u0026quot;$2,$0}' a b 张三|000001|10 000001|10 张三|000001|20 000001|20 李四|000002|30 000002|30 李四|000002|15 000002|15    打印指定行数\n[root@k8s-master01 tmp]# awk '{if(NR==3)print NR\u0026quot;:\u0026quot;$0}' a.txt 3:hello mysql redis ceph [root@k8s-master01 tmp]# awk 'NR==3 {print NR\u0026quot;:\u0026quot;$0}' a.txt 3:hello mysql redis ceph    NF   NF和$NF\nNF表示字段数，在执行过程中对应于当前的字段数。$NF表示最后一列，$(NF_1)表示倒数第二列\n[root@k8s-master01 tmp]# cat a|awk -F \\| '{print $0}' 张三|000001 李四|000002 [root@k8s-master01 tmp]# cat a|awk -F \\| '{print $NF}' 000001 000002 [root@k8s-master01 tmp]# cat a|awk -F \\| '{print $(NF-1)}' 张三 李四 [root@k8s-master01 tmp]# cat a 张三|000001 李四|000002 李四|000002|000004 [root@k8s-master01 tmp]# awk -F \\| '{printf \u0026quot;文件夹%s,第%s行的列个数是%s \\n\u0026quot;, FILENAME,NR,NF}' a 文件夹a,第1行的列个数是2 文件夹a,第2行的列个数是2 文件夹a,第3行的列个数是3    -v 传递外部变量 [root@k8s-master01 tmp]# awk -v asd=\u0026quot;asdasd\u0026quot; -F \\| '{printf \u0026quot;文件夹%s,第%s行的列个数是%s, %s\\n\u0026quot;, FILENAME,NR,NF,asd }' a 文件夹a,第1行的列个数是2, asdasd 文件夹a,第2行的列个数是2, asdasd 文件夹a,第3行的列个数是3, asdasd  awk运算与判断 算术运算符    运算符 描述     + - 加，减   * / \u0026amp; 乘，除与求余   + - ! 一元加，减和逻辑非   ^ *** 求幂   ++ \u0026ndash; 增加或减少，作为前缀或后缀    [root@k8s-master01 tmp]# awk 'BEGIN{a=0}{print a++,++a}' 0 2 2 4 4 6  逻辑运算符    运算符 描述     || 逻辑或   \u0026amp;\u0026amp; 逻辑与    [root@k8s-master01 tmp]# awk 'BEGIN{a=10;b=1;if (a\u0026gt;5 \u0026amp;\u0026amp; a\u0026lt;10) ;print a}' 10 [root@k8s-master01 tmp]# awk 'BEGIN{a=10;b=1;(a\u0026gt;5 \u0026amp;\u0026amp; a\u0026lt;10) ;print a}' 10  正则运算符    运算符 描述     ~ ~! 匹配正则表达式和不匹配正则表达式    [root@k8s-master01 tmp]# awk 'BEGIN{a=\u0026quot;abferbsdasd\u0026quot; ; if (a ~ /^ab/){print a}}' abferbsdasd [root@k8s-master01 tmp]# awk 'BEGIN{a=\u0026quot;sdferbsdasd\u0026quot; ; if (a ~ /^ab/){print a}}'  其它运算符    运算符 描述     $ 字段引用   空格 字符串连接符   ?: C条件表达式   in 数组中是否存在某键值    awk高级输入输出 next 用法 awk中next语句使用：在循环逐行匹配，如果遇到next，就会跳过当前行，直接忽略下面语句。而进行下一行匹配。next语句一般用于多行合并,next是跳出，类似于continue，不执行后面表达式。\n  打印偶数行\n## 第一种方法 [root@k8s-master01 tmp]# awk '{if (NR%2==0){printf \u0026quot;这是第%s行，打印最后一列是%s \\n\u0026quot;, NR,$NF}}'\\n a.txt 这是第2行，打印最后一列是cloudNative 这是第4行，打印最后一列是kafak 这是第6行，打印最后一列是c 这是第8行，打印最后一列是Django ## 第二种方法用next [root@k8s-master01 tmp]# awk '{if (NR%2==1){next}else{printf \u0026quot;这是第%s行，打印最后一列是%s \\n\u0026quot;, NR,$NF}}'\\n a.txt 这是第2行，打印最后一列是cloudNative 这是第4行，打印最后一列是kafak 这是第6行，打印最后一列是c 这是第8行，打印最后一列是Django    数组应用 数组是awk的灵魂，处理文本中最不能少的就是它的数组处理。因为数组索引（下标）可以是数字和字符串在awk中数组叫做关联数组(associative arrays)。awk 中的数组不必提前声明，也不必声明大小。数组元素用0或空字符串来初始化，这根据上下文而定。\n## 统计netstat 状态链接数 [root@k8s-master01 tmp]# netstat -n|awk '/^tcp/ {++S[$NF]} END{for( a in S) print a , S[a]}' ESTABLISHED 250 TIME_WAIT 896 ### /^tcp/ 匹配TCp开头的 ## ++S[$NF] 相当于 s[$NF]=S[$NF]+1 及 0+1，计数tcp状态 ## END 最后输出  时间函数    格式 描述     函数名 说明   mktime( YYYY MM dd HH MM ss[ DST]) 生成时间格式   strftime([format [, timestamp]]) 格式化时间输出，将时间戳转为时间字符串 具体格式，见下表.   systime() 得到时间戳,返回从1970年1月1日开始到当前时间(不计闰年)的整秒数    建指定时间(mktime使用）\nawk 'BEGIN{tstamp=mktime(\u0026quot;2001 01 01 12 12 12\u0026quot;);print strftime(\u0026quot;%c\u0026quot;,tstamp);}' 2001年01月01日 星期一 12时12分12秒 awk 'BEGIN{tstamp1=mktime(\u0026quot;2001 01 01 12 12 12\u0026quot;);tstamp2=mktime(\u0026quot;2001 02 01 0 0 0\u0026quot;);print tstamp2-tstamp1;}' 2634468  求2个时间段中间时间差，介绍了strftime使用方法\nawk 'BEGIN{tstamp1=mktime(\u0026quot;2001 01 01 12 12 12\u0026quot;);tstamp2=systime();print tstamp2-tstamp1;}' 308201392  常见实列 查看tcp链接状况统计 netstat -n|awk '/^tcp/ {++S[$NF]} END{for (i in S) print i,S[i]}'  日志分析(nginx) Nginx内容如下：\n172.16.95.6 - - [27/Jul/2020:00:00:02 +0800] \u0026quot;GET /api/users/system_update.json HTTP/1.0\u0026quot; 200 23 \u0026quot;https://www.educoder.net/classrooms\u0026quot; \u0026quot;Mozilla/5.0 (Linux; U; Android 8.0.0; zh-cn; CMR-W09 Build/HUAWEICMR-W09) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/66.0.3359.126 MQQBrowser/10.4 Mobile Safari/537.36\u0026quot;    统计日志中访问最多的10个IP\n[root@k8s-master01 ~]# awk '{++S[$1]} END{for (i in S) print i,S[i]}' access.log |sort -k 2 -nr|head -10 94.102.50.96 14 172.16.95.6 7 100.122.65.87 6 100.122.64.243 6 100.122.63.246 6 71.6.167.142 5 100.122.64.206 5    统计日志中访问大于4次的IP\n[root@k8s-master01 ~]# awk '{++S[$1]} END{for (i in S) print i,S[i]}' access.log |sort -k 2 -nr|head -10 94.102.50.96 14 172.16.95.6 7 100.122.65.87 6 100.122.64.243 6 100.122.63.246 6 71.6.167.142 5 100.122.64.206 5 100.122.64.156 5 100.122.63.233 5 222.240.101.70 4    统计某个时间区间内访问最多的10个IP\n[root@k8s-master01 ~]# awk '$4 \u0026gt;\u0026quot;[27/Jul/2020:00:00:00\u0026quot; \u0026amp;\u0026amp; $4 \u0026lt;\u0026quot;[27/Jul/2020:00:00:03\u0026quot; {++S[$1]} END{for (i in S) print i, S[i]} ' access.log |sort -k 2 -rn|head -10 172.16.95.6 6 172.16.95.29 2    统计访问的uri 个数排名\n[root@k8s-master01 ~]# awk '{a[$7]++} END{for (i in a) print a[i],i}' access.log |sort -k 1 -nr |head -10 447 / 5 /forums/categories/5 4 /scripts/setup.php 4 /MyAdmin/scripts/setup.php 4 400 3 /robots.txt 3 /pma/scripts/setup.php 2 /phpMyAdmin/scripts/setup.php 2 http://www.baidu.com/cache/global/img/gs.gif 2 http://clientapi.ipip.net/echo.php?info=1234567890    统计每个URL访问内容的总大小（$body_bytes_sent）\n[root@k8s-master01 ~]# awk '{++S[$7];size[$7]+=$10}END{for(i in S) print size[i],i}' access.log |sort -k 1 -nr|head -10 67646 /images/avatars/LaboratorySetting/1tab?t=1581490135 37406 / 2855 /forums/categories/5 2201 /api/attachments/920111 740 /favicon.ico 676 /scripts/setup.php 676 /MyAdmin/scripts/setup.php 612 http://www.baidu.com/ 571 http://www.qq.com/404/search_children.js 507 /pma/scripts/setup.php    统计访问状态码为404的IP及出现次数\n[root@k8s-master01 ~]# grep 400 access.log |awk '{++S[$1]} END{for (i in S) print S[i],i,\u0026quot;Status:400\u0026quot;}' |sort -k 1 -nr 2 120.132.3.65 Status:400 1 59.36.132.222 Status:400 1 213.227.141.152 Status:400 1 185.53.88.54 Status:400 1 110.249.212.46 Status:400    文件内容对比差异处理   对比文件内容，对比文件差异\n## 方法一 awk 'FNR==NR{a[$0];next} !($0 in a)' a b ##方法二 grep -vf a b    ","id":11,"section":"posts","summary":"[ToC] 目的 在实际的生产中能够熟练的使用awk ，sed ，grep等文本操作工具，对故障的快速定位，日志分析等有很大帮助，于是根据自己的实际的生产经","tags":["awk","linux"],"title":"awk工具使用总结","uri":"https://zhangshunping.github.io/2020/05/awk/","year":"2020"},{"content":"四表五链 四表 五链   filter\u0026mdash; 过滤数据包\n  nat \u0026mdash; 用于网络地址转换（IP、端口）\n  raw \u0026mdash; 决定数据包是否被状态跟踪机制处理\n  mangle \u0026mdash;修改数据包的服务类型、TTL、并且可以配置路由实现QOS\n  五链PREROUTING ,INPUT ,OUTPUT ,FORWARD,POSTROUTING\n  命令（增删改查） iptables 查询  -L   iptables -t 表名 -vnL 链名 不指定表名，及为filter表。\n  iptables -vnL --line-number v显示详细说明，n不需要dns解析，\u0026ndash;line-number显示num。\n[root@local-master ~]# iptables -vnL --line-number Chain INPUT (policy ACCEPT 1453 packets, 109K bytes) num pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 2108 packets, 146K bytes) num pkts bytes target prot opt in out source destination  //字典解释 pkts：表示匹配的报文个数 bytes:表示报文包的大小 traget:表示规则对应的动作 prot：表示协议 in： 从哪个接口(网卡)流入 out：从哪个接口（网卡）流出 source：表示对应的源头地址，可以是ip也可以是网段 destination：表示对应的目标地址，可以是ip也可以是网段    iptables 管理   增 -I 或者-A\niptables -t 表名 -I 链名 -s -d -j  在首行增加\niptables -t 表名 -I 链名 2 -s -d -j  增加第二行\niptables -t 表名 -A 链名 -s -d -j  在尾行增加\niptables -t filter -I INPUT -s 192.168.2.35 -j ACCEPT\n  删 -D\niptables -t 表名 -D 链名 第几行\niptables -D INPUT 2\n  改 -R\n用-R，但是不建议使用，一般使用先删除，再增加的方式，如果非要用，必须要指定原来的条件\n如果执行\niptables -R INPUT 3 -j REJECT 则会变成这样，把源地址和目的地址都变成0.0.0.0/0 因此要慎用\n使用 -P 修改链路的默认规则\niptables -P INPUT ACCEPT \n  保存规则\niptables-save \u0026gt;/etc/sysconfig/iptables\niptables-restore \u0026lt; /etc/sysconfig/iptables\n  iptables 条件匹配   源地址条件匹配\niptables -I INPUT -s 192.168.129.2,192.168.3.13 -j ACCEPT 用，配置多个源地址\n源地址取反操作 ！\niptables -I INPUT 2 ! -s 192.168.2.244 -j ACCEPT 这个语句的意思是，如果source ip不是192.168.23.2则往下执行。而不是说非192.168.2.2\n  协议匹配\n-p\niptables -I input -s 192.168.2.244 -p tcp -j REJECT 只限制住tcp，但是icmp不限制\n  网卡匹配：-i -o\n-i 只能用在 PREROUTING，INPUT，FORWARD\n-o 只能用在 OUTPUT，POSTROUTING，FORWARD\niptables -I input -s 192.168.2.244 -i eth0 -p icmp -j REJECT  对 网卡 限制ping\n  iptables条件匹配扩展  tcp模块  ​ -p tcp -m tcp \u0026ndash;dport |\u0026ndash;sport 可以指定连续的端口，也可以指定单个端口，如果不指定-m tcp，则用-p的协议作为模块\n#示列 iptables -I INPUT -p tcp -m tcp --dport :25 -j ACCEPT iptables -I INPUT -p tcp --dport 30: -j ACCEPT iptables -I INPUT -p tcp --dport 2000:4000 -j ACCEPT ## 源地址不是22端口的接受 iptables -I INPUT -p tcp -m tcp ! --sport 22 -j ACCEPT #结果如下： 65 3868 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp spt:!22 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpts:2000:4000 522 26100 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpts:30:65535 154 11068 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpts:0:25    multiport模块\n常用模块，指定离散的多个ip端口，用,隔开\t注意是\u0026ndash;dports和\u0026ndash;sports\n[root@local-master ~]# iptables -I INPUT -p tcp -m multiport --dports 8890,8888 -j DROP [root@local-master ~]# iptables -vnL Chain INPUT (policy ACCEPT 114 packets, 8028 bytes) pkts bytes target prot opt in out source destination 0 0 DROP tcp -- * * 0.0.0.0/0 0.0.0.0/0 multiport dports 8890,8888    iprange模块\n--src-range 指定连续的源地址范围\n--dst-range 指定连续的目的地址范围\n iptables -I INPUT -m iprange --src-range 192.168.2.1-192.168.2.244 -j ACCEPT\n  string 模块 ，过滤关键字\n  time 模块 ， 指定时间放行\n  connlimt模块，限制ip的链接数量\n  limit模块\n--limit-burst 类似“令牌桶”算法，用于指定令牌桶的最大上限\n--limit ，类似\u0026quot;令牌桶\u0026quot;算法，指定令牌桶的生产新令牌的频率，可用时间为second，minute，hour，day\n###例 ##限制ping的速率 // 最大令牌为3个，每一分钟生成30个令牌，相当于每两秒钟生成一个令牌，及每两秒钟放行一个 iptables -I INPUT -p icmp -m limit --limit-burst 3 --limit 30/minute -j ACCEPT //如果iptables 的默认规则为ACCEPT，需要用REJECT做往下匹配限制 iptables -A INPUT -p icmp -j REJECT    ","id":12,"section":"posts","summary":"四表五链 四表 五链 filter\u0026mdash; 过滤数据包 nat \u0026mdash; 用于网络地址转换（IP、端口） raw \u0026mdash; 决定数据包是否被状态跟踪机制处理 mangle \u0026mdash;修改数据包的服务类型、TT","tags":["iptables","linux"],"title":"Iptables(一)","uri":"https://zhangshunping.github.io/2020/05/iptables-1/","year":"2020"},{"content":"[TOC]\nstate 模块   对于state模块的连接而言，\u0026ldquo;连接\u0026quot;其中的报文可以分为5种状态，报文状态可以为NEW、ESTABLISHED、RELATED、INVALID、UNTRACKED\n  NEW: 新连接得第一个包为new\n  ESTABLISHED: NEW状态包后面的包的状态理解为ESTABLISHED，表示已建立链接\n  RELATED：有些报文返回是需要多个进程直接相互配合进项，比如FTP服务命令进程和数据进程是有关系的，因此数据链接的报文可能就是RELATED，因为他是由命令进程控制的。\n  INVALID: 报文没有被识别，包没有状态，包的状态INVALID，可以主动屏蔽INVALID的报文\n  UNTRACED:报文没有被追踪，表示无法找到相关的链接\n    因此：客户端，怎样判断这些报文是为了回应我们之前发出的报文，还是主动向我们发送的报文呢？\niptables -t fiflter -I INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT  则表示，客户端不允许被主动发起报文。\n黑白名单   方式一：（不推荐）设置链路的默认规则为DROP\\\n##1、 设置链路的默认规则为Drop iptables -P INPUT DROP ##2、放行 iptables -I INPUT --dport 80 -j ACCEPT ## 问题 如果不小心执行iptahles -F 的会导致所有请求无法访问    方式二：（推荐）设置链路的默认规则为ACCEPT，在末尾设置DROP\niptables -P INPUT -j ACCEPT iptables -I INPUT --dport 80 -j ACCEPT iptables -A INPUT -j DROP    自定义链路 创建自定义链路 #1. -N 创建自定义表 iptables -t filter -N IN_WEB #2. 常看自定义表 iptables --line -vnL IN_WEB ##显示如下 ： 0 references 表示没有被引用  #3、在默认链路上引用IN_WEB ## 在INPUT链路上插入规则，表示访问80的端口，跳转到IN_WEB自定义链路上 iptables -I INPUT -p tcp --dport 80 -j IN_WEB [root@k8s-master01 ~]# iptables -vnL INPUT Chain INPUT (policy ACCEPT 273 packets, 24366 bytes) pkts bytes target prot opt in out source destination 2 120 IN_WEB tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 8339 783K KUBE-EXTERNAL-SERVICES all -- * * 0.0.0.0/0 0.0.0.0/0 ctstate NEW /* kubernetes externally-visible service portals */ 828K 177M KUBE-FIREWALL all -- * * 0.0.0.0/0 0.0.0.0/0 [root@k8s-master01 ~]# iptables -vnL IN_WEB Chain IN_WEB (1 references) ## 这里的 references为1 表示被引用一次 pkts bytes target prot opt in out source destination 2 120 REJECT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 reject-with icmp-port-unreachable [root@k8s-master01 ~]# curl 127.0.0.1 curl: (7) Failed connect to 127.0.0.1:80; 拒绝连接  重命名自定义链路 -E [root@k8s-master01 ~]# iptables -E IN_WEB IN_WEB2 [root@k8s-master01 ~]# iptables -vnL INPUT Chain INPUT (policy ACCEPT 63 packets, 5259 bytes) pkts bytes target prot opt in out source destination 4 240 IN_WEB2 tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 8491 798K KUBE-EXTERNAL-SERVICES all -- * * 0.0.0.0/0 0.0.0.0/0 ctstate NEW /* kubernetes externally-visible service portals */ 828K 177M KUBE-FIREWALL all -- * * 0.0.0.0/0 0.0.0.0/0 [root@k8s-master01 ~]# iptables -vnL IN_WEB2 Chain IN_WEB2 (1 references) pkts bytes target prot opt in out source destination 4 240 REJECT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 reject-with icmp-port-unreachable  删除自定义链路 -X ##删除链路需要满足 ## 1、自定义链没有被任何默认链引用，即自定义链的引用计数为0。 ##2、自定义链中没有任何规则，即自定义链为空。 [root@k8s-master01 ~]# iptables -X IN_WEB2 iptables: Too many links. [root@k8s-master01 ~]# iptables -D INPUT 1 ## 清空引用链路 [root@k8s-master01 ~]# iptables -X IN_WEB2 iptables: Directory not empty. [root@k8s-master01 ~]# iptables -F IN_WEB2 ## 清空规则 [root@k8s-master01 ~]# iptables -X IN_WEB2  Iptables网络防火墙 1、需求： 主机A访问主机C，A和C不在同一个网络，借助主机B的iptables路由规则 ##主机A,添加路由，去往192.168.181.0（外网）的报文的下一跳为主机B route add -net 192.168.181.0/24 gw 192.168.2.17 ##主机C，添加路由，去往192.168.2.0(外网的报文)的下一跳为主机B route add -net 192.168.2.0/24 gw 192.168.2.17 ## 主机B 永久开启路由转发 vim /etc/sysctl.conf net.ipv4.ip_forward ## 临时开启 echo 1 \u0026gt;/proc/sys/net/ipv4/ip_forward ##主机B设置黑名单 iptables -t filter -P FORWARD ACCEPT iptables -A FORWARD DROP iptables -E FORWARD_TEST iptables -I FORWARD_TEST -s 192.168.2.0/24 -j ACCEPT iptables -I FORWARD_TEST -s 192.168.181.0/24 -j ACCEPT iptables -I FORWARD -j FORWARD_TEST  2、通过snat，dnat转发。实现公网端口暴露和私网上网  模型如下，主机A为公网客户都安，主机B为公司iptables linux，主机C为内网主机    操作步骤\n#主机B需开启路由 vim /etc/sysctl.conf net.ipv4.ip_forward # 添加snat配置(允许私网通过B主机的ip，访问A) iptables -t nat -I POSTROUTING -s 192.168.181.0/24 -j SNAT --to-source=192.168.2.17 # 添加dnat配置（A访问B的122端口，即可访问C主机的22端口 iptables -t dnat -I PREROUTING -d 192.168.2.18 -p tcp --dport 122 --to-destination=192.168.181.129:22 ##同时检查 filter表上是否有限制操作 iptables -t filter -vnL FORWARD ## 主机c需要添加路由 route add default gw 192.168.181.128    dnat和snat转发，普通路由转发的区别   共同点\n 都需要linux 开启路由转发功能 私有主机，及C主机都需要配置下一跳到B主机    不同点\n  dnat和snat 是描述的私网和公网的情况，因此主机A配置route 到B是广播不可达的；而但单纯的路由转发一般在同一二层网络中（比如vmware开启三台主机）\n  dnat和snat 完成的地址转换，经过B主机之后，ip的地址都会变成B主机的地址；而单纯的路由转发，ip地址不变\n  MASQUSEADE  可以把MASQUERADE理解为动态的、自动化的SNAT，如果没有动态SNAT的需求，没有必要使用MASQUERADE，因为SNAT更加高效。  iptables -t nat -I POSTROUTING -s 192.168.181.0/24 -o ens32 -j MASQUSEADE  REDIRECT动作可以在本机上进行端口映射   比如，将本机的80端口映射到本机的8080端口上\niptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 8080\n经过上述规则映射后，当别的机器访问本机的80端口时，报文会被重定向到本机的8080端口上。\nREDIRECT规则只能定义在PREROUTING链或者OUTPUT链中。\n  iptables 注意点：  针对相同服务的时候，严格的规则应该放在前面 当规则中有多个匹配条件时，条件之间默认存在\u0026quot;与\u0026quot;的关系 在不考虑1的情况下，应该将更容易被匹配到的规则放置在前面，通过iptables -vnL 查看（pkts计数） 当IPTABLES所在主机作为网络防火 墙时，在配置规则时，应着重考虑方向性，双向都要考虑，从外到内，从内到外 设置防护墙白名单的时候，默认规则应为ACCEPT，在某行增加DROP动作，防止iptables -F 导致不可登陆  ","id":13,"section":"posts","summary":"[TOC] state 模块 对于state模块的连接而言，\u0026ldquo;连接\u0026quot;其中的报文可以分为5种状态，报文状态可以为NEW、ESTABLISHED","tags":["iptables","linux"],"title":"Iptables(二)","uri":"https://zhangshunping.github.io/2020/05/iptables-2/","year":"2020"},{"content":"channle 都是应用于两个go程，一个读，一个写  channel 具有阻塞的作用，类似go程之间对同步资源进行锁机制 具有数据传递的功能  一、无缓冲channel \u0026mdash;-（同步） 无缓冲channel 定义  var ch =make(chan string ) 或者ch :=make(chan string)  无缓冲channel的说明  ch \u0026lt;- \u0026ldquo;hehe\u0026rdquo; 写数据，数据没有被在读，则为阻塞 \u0026lt;-ch 读数据，数据没有没有在写， 则为阻塞 len(ch) ：channel中未读取的元素个数，cap(ch):channel中通道的容量 。 都是零  二、有缓冲channel \u0026mdash;\u0026mdash;（异步） 有缓冲channel定义  var ch =make(chan string ,3) 或者ch :=make(chan string ,3) 当存储的元素个数超过了cap(ch) 才会阻塞  三、关闭channel   close(ch) ，不再向对端发送数据\n  判断chan是否关闭 ，\nif num,ok:=\u0026lt;-chan; ok ==true{ fmt.Println(\u0026quot;已经关闭\u0026quot;) } // 无缓冲 关闭channle，读端 ok为false，num为0 // 如果channel已经关闭 ，写端出现panic send on closed channel // 如果channle有缓冲，当len(ch) 的值没有超过cap(ch),那么close(ch)是阻塞的 // 如果channle无缓冲，当ch中存在元素，close（ch）也是阻塞的 func main() { ch:=make(chan int) go func() { for i:=0;i\u0026lt;=100;i++{ ch \u0026lt;-i } close(ch) //这里close其实是阻塞的 }() go func() { for{ if num,ok:=\u0026lt;-ch;ok{ fmt.Print(num) close(ch) }else{ fmt.Println(\u0026quot;jieshu\u0026quot;,num) } } }()    四、单向channel   双向channel ch:=make(chan string )\n  单项写channel var readCh chan\u0026lt;- int\n  单向读channel var writech \u0026lt;-chan\n  单向channel和双向channel转换  双向转单向 readch = ch 单向不可以转双向  传参：传【引用】 Channel通信的时候，要保证channle不能在同一个go程之中\n五、消费者，生产者模型  解耦（降低消费者和生产者直接的耦合度） 并发（消费者，生产者消费不对等，能保持正常的通信） 缓存（生产者和消费者处理不一致时，暂存数据）  生产者，消费者实现：  - 有缓冲的channel ：异步同行 - 无缓冲的channel：同步通信  package main import \u0026quot;fmt\u0026quot; type Orderinfo struct { id int price int } func producer(ch chan\u0026lt;- Orderinfo) { for i:=0;i\u0026lt;=1000;i++{ ch\u0026lt;-Orderinfo{id:i+1,price: 10} } close(ch) } func consumer(ch \u0026lt;-chan Orderinfo) { for order:=range(ch){ fmt.Println(\u0026quot;订单价格：\u0026quot;,order.price,\u0026quot;订单编号：\u0026quot;,order.id) } } func main() { ch :=make(chan Orderinfo) go producer(ch) consumer(ch) }  六、定时器: 三种定义方法 time.sleep() ; time.NewTimer() ;time.After() package main import ( \u0026quot;fmt\u0026quot; \u0026quot;time\u0026quot; ) func main() { //time.sleep定时 fmt.Println(\u0026quot;当前时间\u0026quot;,time.Now()) time.Sleep(time.Second*1) fmt.Println(\u0026quot;time.sleep定时当前时间\u0026quot;,time.Now()) //time.Newtimer // 创建定时器 t:=time.NewTimer(time.Second*1) now:=\u0026lt;-t.C fmt.Println(\u0026quot;time.NewTimer阻塞 t.C管道读取系统当前时间为：\u0026quot;,now) //time.After 返回一个管道 now=\u0026lt;-time.After(time.Second) fmt.Println(\u0026quot;time.After，系统chan写满，则返回当前时间：\u0026quot;,now) }  七、select 语句 select (退出for 循环中的select ，用return 或者goto的方式)\nfunc main() { ch:=make(chan int) quit:=make(chan bool) fmt.Println(\u0026lt;-time.After(time.Second)) go func() { for{ select { case num:=\u0026lt;-ch: fmt.Println(\u0026quot;nume\u0026quot;,num) case \u0026lt;-time.After(time.Second*3): fmt.Println(\u0026quot;超时\u0026quot;) quit\u0026lt;-true //return goto loop } } loop: fmt.Println(\u0026quot;for end\u0026quot;) }() for i:=0;i\u0026lt;4;i++{ ch\u0026lt;-i time.Sleep(time.Second) } \u0026lt;-quit }  八、锁 golang死锁模型：  1、单go程自己死锁： channel至少在两个go程中使用，否则思索 2、go程间channel访问顺序：使用channle一端写（读），要保证另一一段读（写），同时有机会执行，否则思索 3、多go程，多channel交叉死锁 4、在go语言中，尽量不要将互斥锁和channel一起使用，会造成隐形死锁  golang 锁  1.channel 定义互斥锁  //定义个全局channel var ch =make(chan string) func Printer(s string){ for _,s1:=range(s){ fmt.Print(string(s1)) \u0026lt;-time.After(time.Microsecond*500000) } } func main() { //go程里结束，向ch中传递 go func() { Printer(\u0026quot;hello\u0026quot;) ch\u0026lt;-\u0026quot;ok\u0026quot; close(ch) }() // 主go程在阻塞等待 \u0026lt;-ch Printer(\u0026quot;world\u0026quot;) }    2.用锁定义互斥锁（这种锁，我们一般称为:\u0026ndash;\u0026gt;建议锁)\nvar mutex sync.Mutex //定义锁 //对共享资源枷锁 mutex.Lock() fmt.Pirnt('hello') muter.Unlock()    3.读写锁: 读时共享，写时独占（写比读优先级要高）\n var rwmutex2 sync.RWMutex 定了一把锁，这个锁带有读和写的属性  var rwmutex2 sync.RWMutex var I int func reader2(i int){ for{ // 读锁，并发共享 rwmutex2.RLock() a:=I rwmutex2.RUnlock() fmt.Printf(\u0026quot;=======第%d个读进程,读取到%d\\n\u0026quot;,i,a) time.Sleep(time.Second) } } func writer2(a int){ for{ num:=rand.Intn(100) // 写锁，独占 rwmutex2.Lock() I=num fmt.Printf(\u0026quot;第%dth写go程,写数据:%d \\n\u0026quot; ,a,num) time.Sleep(time.Second*2) rwmutex2.Unlock() } } func main(){ for i:=0;i\u0026lt;=3;i++{ go reader2(i) } for i:=0;i\u0026lt;=3;i++{ go writer2(i) } for{ ; } }   channel 无法完成共享读，因此需要对读完成共享数据读的时候，使用读写锁    条件变量 type Cond struct   适用生产者消费者模型：本身不是锁，经常要与锁结合使用,他是一个结构体\n  作用：\n 加锁 访问公共区域（比如带缓冲channle） 解锁 唤醒阻塞在条件变量上对端    条件变量Cond常见方法：\n  wait（） 函数 使用场景\n 阻塞等待条件变量满足 释放已掌握的互斥锁相当于 cond.L.Unlock() ;注意：两步分为原子操作 \u0026lt;\u0026mdash;-及不可以分开 当被唤醒，Wati（）函数返回时候，解决阻塞并重新获取互斥锁。相当于cond.L.Lock()    cond.Single() 唤醒对端\n  cond.Broadcast()惊群唤醒\n    创建条件变量流程\n//1.创建条件变量 var cond sync.Cond //2.创建条件变量指定锁 cond.L=new(sync.Mutex) //3. 给公共区加锁 cond.L.Lock() //4.判断是否达到阻塞条件 // //4.1 producer 端判断条件 for len(ch)==cap(ch){ cond.Wait() //1.阻塞2.解锁 3.加锁 } //4.2 consumer端判断 for len(ch)==0{ cond.Wait() } //5.访问公共区，读写，打印 //6.对公共区条件变量解锁 cond.L.Unlock() //7.唤醒阻塞在条件变量对端 cond.Single()  【条件变量示例】\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;sync\u0026quot; \u0026quot;time\u0026quot; ) //1.创建条件变量 var cond sync.Cond func producer2(product chan\u0026lt;- string,index int) { //3.使用条件变量给公共区加锁 cond.L.Lock() //4. 判断是否已经填满缓冲区，如果填满则wait() for len(product)==cap(product){ cond.Wait() } //5.执行写操作 str:=fmt.Sprintf(\u0026quot;produce%d\u0026quot;,index) product\u0026lt;-str fmt.Printf(\u0026quot;这是第%d个producer进程,produce %q \\n\u0026quot;,index,str) time.Sleep(time.Millisecond*200) // 6.解锁 cond.L.Unlock() //7.唤醒阻塞的对端 cond.Signal() } func consumer2(product \u0026lt;-chan string,index int) { for{ cond.L.Lock() for len(product)==0{ cond.Wait() } str\t:=\u0026lt;-product fmt.Printf(\u0026quot;--------这是第%d个consumer进程,consum %s \\n\u0026quot;,index,str) cond.L.Unlock() cond.Signal() } } func main() { product:=make(chan string,3) // 2.指定条件变量用的锁为互斥锁 cond.L=new(sync.Mutex) for i:=1;i\u0026lt;=1000;i++{ go producer2(product,i) } for i:=1;i\u0026lt;=3;i++{ go consumer2(product,i) } for{ ; } }    ","id":14,"section":"posts","summary":"channle 都是应用于两个go程，一个读，一个写 channel 具有阻塞的作用，类似go程之间对同步资源进行锁机制 具有数据传递的功能 一、无缓冲channel \u0026mda","tags":["golang-channel"],"title":"Golang-Channel","uri":"https://zhangshunping.github.io/2020/05/golang-channel/","year":"2020"},{"content":" rysnc 常用选项 rsync常用选项 -a 包含-rtplgoD -r 同步目录时要加上，类似cp时的-r选项 -v 同步时显示一些信息，让我们知道同步的过程 -l 小写l保留软连接，例如A机器上面的文件有软连接所指向的文件，同步到B机器时同样也保留软连接。 -L 大写L加上该选项后，同步软链接时会把源文件给同步 -p 小写p保持文件的权限属性 -o 保持文件的属主 -g 保持文件的属组 -D 保持设备文件信息 -t 保持文件的时间属性 --delete 删除DEST中SRC没有的文件 --exclude 过滤指定文件，如--exclude “logs”会把文件名包含logs的文件或者目录过滤掉，不同步 -P 大写P显示同步过程，比如速率，比-v更加详细 -u 加上该选项后，如果DEST中的文件比SRC新，则不同步 -z z表示zip传输时压缩，传输到目标点后自动就解压了，只是在传输前或传输过程中减少网络资源带宽。 --existing ：要求只更新目标端已存在的文件，目标端还不存在的文件不传输。注意，使用相对路径时如果上层目录不存在也不会传输。 --ignore-existing：要求只更新目标端不存在的文件。和\u0026quot;--existing\u0026quot;结合使用有特殊功能，见下文示例。 --delete ：以SRC为主，对DEST进行同步。多则删之，少则补之。注意\u0026quot;--delete\u0026quot;是在接收端执行的，所以它是在 ：exclude/include规则生效之后才执行的。 -d --dirs ：以不递归的方式拷贝目录本身。默认递归时，如果源为\u0026quot;dir1/file1\u0026quot;，则不会拷贝dir1目录，使用该选项将拷贝dir1但不拷贝file1。 -u --update ：仅在源mtime比目标已存在文件的mtime新时才拷贝。注意，该选项是接收端判断的，不会影响删除行为。  常用命令 拷贝复制   ## 将/home/bridg.war 增量同步到/tmp/下 命名为bridge2.war rsync -Pzav /home/bridge.war /tmp/bridge2.war ## 将/home/bridg.war 增量同步到/tmp/ rsync -Pzav /home/bridge.war /tmp/ ## --delete的使用 ，删除DEST中SRC没有的文件 ##注意：src目录没有的，dst目录也会被删掉 [root@k8s-master01 /tmp/tmp.V8GRsfNIeG]# tree ./ ./ ├── t1 │ ├── a │ ├── b │ └── c └── t2 ├── a └── c [root@k8s-master01 /tmp/tmp.V8GRsfNIeG]# rsync -Pzav --delete t2/ t1/ [root@k8s-master01 /tmp/tmp.V8GRsfNIeG]# tree ./ ./ ├── t1 │ ├── a │ └── c └── t2 ├── a └── c    过滤 --exclude\n[root@k8s-master01 /tmp/tmp.V8GRsfNIeG]# ll t2/ 总用量 0 -rw-r--r-- 1 root root 0 5月 21 11:35 a -rw-r--r-- 1 root root 0 5月 21 11:35 c [root@k8s-master01 /tmp/tmp.V8GRsfNIeG]# ll t1/ 总用量 0 -rw-r--r-- 1 root root 0 5月 21 11:35 a -rw-r--r-- 1 root root 0 5月 21 11:35 c -rw-r--r-- 1 root root 0 5月 21 11:41 jss.js -rw-r--r-- 1 root root 0 5月 21 11:41 readme.txt [root@k8s-master01 /tmp/tmp.V8GRsfNIeG]# rsync -av --exclude \u0026quot;*.js\u0026quot; --exclude \u0026quot;*.txt\u0026quot; t1/ t2/ ## 显示结果js和txt并未拷贝 [root@k8s-master01 /tmp/tmp.V8GRsfNIeG]# ll t2/ 总用量 0 -rw-r--r-- 1 root root 0 5月 21 11:35 a -rw-r--r-- 1 root root 0 5月 21 11:35 c [root@k8s-master01 /tmp/tmp.V8GRsfNIeG]# ll t1/ 总用量 0 -rw-r--r-- 1 root root 0 5月 21 11:35 a -rw-r--r-- 1 root root 0 5月 21 11:35 c -rw-r--r-- 1 root root 0 5月 21 11:41 jss.js -rw-r--r-- 1 root root 0 5月 21 11:41 readme.txt    使用sshpasss, ssh 远程同步\nsshpass -p 123123 rsync -av -e \u0026quot;ssh -p 22\u0026quot; root@127.0.0.1:/tmp/t2/ /tmp/t1/    ​\n  使用rsync 删除大文件\n## 在遇到很大的目录时候，使用rm去删除，会出现报错 ##先创建一个空目录 mkdir /tmp/empty/ ## 清空目标目录 # rsync --delete-before -avH --progress --stats /tmp/empty/ /var/spool/postfix/maildrop rsync --delete -rlptD /tmp/empty/ /var/spool/postfix/maildrop/ ##选项说明： -delete-before 接收者在传输之前进行删除操作 –progress 在传输时显示传输过程 -a 归档模式，表示以递归方式传输文件，并保持所有文件属性 -H 保持硬连接的文件 -v 详细输出模式 –stats 给出某些文件的传输状态 ## 注意： ## 不过在使用上面的命令进行清理时，存在一个问题，清空后，目标目录的权限会和源目录的权限一样。如：/tmp/empty是root：root，而maildrop之前是postfix：postdrop ，执行之后也会maildrop目录的权限也会变成root：root 。由于-a权限是-rlptogD几个参数的集合，所以可以将og（owner:group）两个参数去掉。清空时自动保持之前的目录权限，如下： rsync --delete -rlptD /tmp/empty/ /var/spool/postfix/maildrop/    ","id":15,"section":"posts","summary":"rysnc 常用选项 rsync常用选项 -a 包含-rtplgoD -r 同步目录时要加上，类似cp时的-r选项 -v 同步时显示一些信息，让我们知道同步的过程 -l 小写l","tags":["Linux","rync"],"title":"Rsync","uri":"https://zhangshunping.github.io/2020/05/rsync/","year":"2020"},{"content":" curl -o /dev/null -s -w %{time_namelookup}---%{time_connect}---%{time_starttransfer}---%{time_total}---%{speed_download}\u0026quot;\\n\u0026quot;  查看链接\n[root@pre-host-work02 ~]# curl -o /dev/null -s -w %{time_namelookup}---%{time_connect}---%{time_starttransfer}---%{time_total}---%{speed_download}\u0026quot;\\n\u0026quot; https://test-newweb.educoder.net/api/myshixuns/training_task_status.json\r0.004---31.731---34.086---34.086---1.000\r ","id":16,"section":"posts","summary":"curl -o /dev/null -s -w %{time_namelookup}---%{time_connect}---%{time_starttransfer}---%{time_total}---%{speed_download}\u0026quot;\\n\u0026quot; 查看链接 [root@pre-host-work02 ~]# curl -o /dev/null -s -w %{time_namelookup}---%{time_connect}---%{time_starttransfer}---%{time_total}---%{speed_download}\u0026quot;\\n\u0026quot; https://test-newweb.educoder.net/api/myshixuns/training_task_status.json 0.004---31.731---34.086---34.086---1.000","tags":null,"title":"","uri":"https://zhangshunping.github.io/1/01/curl/","year":"0001"},{"content":"表定义 type Like struct {\rID int `gorm:\u0026quot;primary_key\u0026quot;`\rIp string `gorm:\u0026quot;type:varchar(20);not null;index:ip_idx\u0026quot;`\rUa string `gorm:\u0026quot;type:varchar(256);not null;\u0026quot;`\rTitle string `gorm:\u0026quot;type:varchar(128);not null;index:title_idx\u0026quot;`\rHash uint64 `gorm:\u0026quot;unique_index:hash_idx;\u0026quot;`\rCreatedAt time.Time\r}\r 创建表 if !db.HasTable(\u0026amp;Like{}) {\rif err := db.Set(\u0026quot;gorm:table_options\u0026quot;, \u0026quot;ENGINE=InnoDB DEFAULT CHARSET=utf8\u0026quot;).CreateTable(\u0026amp;Like{}).Error; err != nil {\rpanic(err)\r}\r}\r 增 like := \u0026amp;Like{\rIp: ip,\rUa: ua,\rTitle: title,\rHash: murmur3.Sum64([]byte(strings.Join([]string{ip, ua, title}, \u0026quot;-\u0026quot;))) \u0026gt;\u0026gt; 1,\rCreatedAt: time.Now(),\r}\rif err := db.Create(like).Error; err != nil {\rreturn err\r}\r 先构造已给对象，直接调用 db.Create() 就可以插入一条记录了\n删除 if err := db.Where(\u0026amp;Like{Hash: hash}).Delete(Like{}).Error; err != nil {\rreturn err\r}\r 查询 var count int\rerr := db.Model(\u0026amp;Like{}).Where(\u0026amp;Like{Ip: ip, Ua: ua, Title: title}).Count(\u0026amp;count).Error\rif err != nil {\rreturn false, err\r}\r 修改 db.Model(\u0026amp;user).Update(\u0026quot;name\u0026quot;, \u0026quot;hello\u0026quot;)\rdb.Model(\u0026amp;user).Updates(User{Name: \u0026quot;hello\u0026quot;, Age: 18})\rdb.Model(\u0026amp;user).Updates(User{Name: \u0026quot;\u0026quot;, Age: 0, Actived: false}) // nothing update\r ","id":17,"section":"posts","summary":"表定义 type Like struct { ID int `gorm:\u0026quot;primary_key\u0026quot;` Ip string `gorm:\u0026quot;type:varchar(20);not null;index:ip_idx\u0026quot;` Ua string `gorm:\u0026quot;type:varchar(256);not null;\u0026quot;` Title string `gorm:\u0026quot;type:varchar(128);not null;index:title_idx\u0026quot;` Hash uint64 `gorm:\u0026quot;unique_index:hash_idx;\u0026quot;` CreatedAt time.Time } 创建表 if !db.HasTable(\u0026amp;Like{}) { if err := db.Set(\u0026quot;gorm:table_options\u0026quot;, \u0026quot;ENGINE=InnoDB DEFAULT CHARSET=utf8\u0026quot;).CreateTable(\u0026amp;Like{}).Error; err != nil { panic(err) } } 增 like := \u0026amp;Like{ Ip: ip, Ua: ua, Title: title, Hash: murmur3.Sum64([]byte(strings.Join([]string{ip, ua, title}, \u0026quot;-\u0026quot;))) \u0026gt;\u0026gt; 1, CreatedAt: time.Now(), } if err","tags":null,"title":"","uri":"https://zhangshunping.github.io/1/01/gorm/","year":"0001"},{"content":"[TOC]\nGrpc Prototbuf 协议 protobuf是由Google开发的一种数据序列化协议，可以把它想象成是XML或JSON格式，但更小，更快更简洁。而且一次定义，可生成多种语言的代码。\n一、golang Protocol 环境配置   Protocol 命令下载\n  安装protoc-gen-go.exe go get -u github.com/golang/protobuf/protoc-gen-go\n  golang 安装Protoful插件\n  二、编译生成中间文件 Prod.proto 文件\nsyntax = \u0026quot;proto3\u0026quot;;\rpackage service;\rmessage HelloWorldRequest {\rstring greeting = 1;\r}\rmessage HelloWorldResponse {\rstring reply = 1;\r}\r 用protoc 编译:\n## 胜场Prod.pd.go 文件 protoc.exe --go_out=./services/ pdfiles/Prod.proto  三、编译生成Grpc中间文件\ncd pdfiles; protoc.exe --go_out=plugins=grpc:../services/ Prod.proto\r ","id":18,"section":"posts","summary":"[TOC] Grpc Prototbuf 协议 protobuf是由Google开发的一种数据序列化协议，可以把它想象成是XML或JSON格式，但更小，更快更简洁。而且一次定义，","tags":null,"title":"","uri":"https://zhangshunping.github.io/1/01/grpc%E4%B8%80/","year":"0001"},{"content":"[TOC]\nIstio版本 \u0026gt;=1.5 安装 ## kubernetes上安装istioctl\r##1. istio安装 profile为demo的istio 集群\ristioctl manifest apply --set profile=demo\r##2. 修改ingeress 如果没有loadbalance 则修改为 nodeport\rkubectl patch svc istio-ingressgateway -nistio-system -p '{\u0026quot;spec\u0026quot;:{\u0026quot;type\u0026quot;:\u0026quot;NodePort\u0026quot;}}'\r##3. kubectl get all -nistio-system\r##4. 卸载istio\ristioctl manifest generate --set profile=demo | kubectl delete -f -\r Istioctl 使用 profile istioctl profile list\ristioctl profile dump default \u0026gt;default.yaml ## 一般对端口修改的时候可以使用这样的方式dump下来,修改完之后执行\r## istioctl manifest apply -f defaul.yaml  Inject 解释：Inject Envoy sidecar into Kubernetes pod resources（针对service ，secrete,configmap 资源不起作用）。\n 主动注入envoy sidecar  istioctl kube-inject -f deploynginx.yaml |kubectl apply -f - -n default\r  自动注入  ## 给命名空间打入标签 istio-injection=enable, 则在此命令空间下的资源，都会被自动注入sidecar。\ristioctl label ns jixu istio-injection=enabled\r   istio-proxy 运行原理\n  ​\n如图： nginx Pod中会同时启动三个容器分别是：\n  initContainer\n 执行 istio-iptables脚本创建istio的四个链路，创建完之后退出    Istio-Proxy(istio-pilot,envoy)\n[root@k8s-slave01 ~]# kubectl exec -it nginx-64759d697c-mgxqb -c istio-proxy -- ps -ef\rUID PID PPID C STIME TTY TIME CMD\ristio-p+ 1 0 0 08:12 ? 00:00:00 /usr/local/bin/pilot-agent proxy\ristio-p+ 19 1 0 08:12 ? 00:00:01 /usr/local/bin/envoy -c etc/isti\ristio-p+ 51 0 0 08:15 pts/0 00:00:00 ps -ef\r  运行istio\u0026ndash;agent,根据pilot-discovery 同步数据（pilot-discovery是运行在k8s istio-system下的istiod服务端，它watch kube-apiserver的变化，当用户对k8s资源进行操作时，istiod会同步 api-server的资源，istio-proxy中的istio-agent容器sync istio-disvoery的配置规则，istio-agent将配置文件策略和行为告诉envoy，从而实现对流量控制和行为管理） envoy 是一个轻量级的代理服务。    nginx Container\n web业务容器    注意小技巧：initContainer和istio-proxy用的时同一个镜像，而initContainer执行完istio-iptables脚本之后，就退出，Iistio-agent一直运行是因为,\n镜像中的entypoint是\n \u0026quot;Entrypoint\u0026quot;: [\r\u0026quot;/usr/local/bin/pilot-agent\u0026quot;\r initContainers 中使用的command\nenableServiceLinks: true\rinitContainers:\r- Commnads:\r- istio-iptables\r k8s 中的command覆盖dockerfile中entryPoint， 不过istio 1.65不再使用这种方式，initContainer直接是args，可能对命令做了封装。\nIstio Traffic Management 流量管理简单点就是：使用策略控制流量的流向和大小。\n同时，业务代码只需要关注业务，超时和重连等机制直接交给istio流量管理即可。\nIstio Architecture：（istio 1.5之后）\n 数据面流量：业务之间调用的流量 控制面流量：istio各组件之间配置和控制网格行为的流量  Istio virtual service   概念： virtual service 是一个抽象概念，简单点可以认为是一个virtual service 是一个类似nginx.conf中location 这样的片段文件\n  配置：\n hosts filed： 可配置为 短域名（servicename),长域名(servicename.namesapce.default.local.cluster) 和ingress controller    ","id":19,"section":"posts","summary":"[TOC] Istio版本 \u0026gt;=1.5 安装 ## kubernetes上安装istioctl ##1. istio安装 profile为demo的istio 集群 istioctl manifest apply --set profile=demo ##2. 修改i","tags":null,"title":"","uri":"https://zhangshunping.github.io/1/01/istio-1/","year":"0001"},{"content":"下载 kubernetes  windows 保持软连接  git -c core.symlinks=true clone https://github.com/kubernetes/kubernetes -b release-1.16\r ","id":20,"section":"posts","summary":"下载 kubernetes windows 保持软连接 git -c core.symlinks=true clone https://github.com/kubernetes/kubernetes -b release-1.16","tags":null,"title":"","uri":"https://zhangshunping.github.io/1/01/kubelet/","year":"0001"},{"content":"title: \u0026quot;Prometheus（一）\u0026quot;\rdate: 2020-08-16T11:59:59+08:00\rtags: [监控,prometheus]\rcategories: [云原生]\rdescription: \u0026quot;Promethues笔记\u0026quot;\tshowDate: true/false math: true  [toc]\n 监控的目的 在《SRE: Google运维解密》一书中指出，监控系统需要能够有效的支持白盒监控和黑盒监控。通过白盒能够了解其内部的实际运行状态，通过对监控指标的观察能够预判可能出现的问题，从而对潜在的不确定因素进行优化。而黑盒监控，常见的如HTTP探针，TCP探针等，可以在系统或者服务在发生故障时能够快速通知相关的人员进行处理。通过建立完善的监控体系，从而达到以下目的：\n 长期趋势分析：通过对监控样本数据的持续收集和统计，对监控指标进行长期趋势分析。例如，通过对磁盘空间增长率的判断，我们可以提前预测在未来什么时间节点上需要对资源进行扩容。 对照分析：两个版本的系统运行资源使用情况的差异如何？在不同容量情况下系统的并发和负载变化如何？通过监控能够方便的对系统进行跟踪和比较。 告警：当系统出现或者即将出现故障时，监控系统需要迅速反应并通知管理员，从而能够对问题进行快速的处理或者提前预防问题的发生，避免出现对业务的影响。 故障分析与定位：当问题发生后，需要对问题进行调查和处理。通过对不同监控监控以及历史数据的分析，能够找到并解决根源问题。 数据可视化：通过可视化仪表盘能够直接获取系统的运行状态、资源使用情况、以及服务运行状态等直观的信息。   Promql 什么是时间序列 通过Node Exporter暴露的HTTP服务，Prometheus可以采集到当前主机所有监控指标的样本数据。例如：\n# HELP node_cpu Seconds the cpus spent in each mode.\r# TYPE node_cpu counter\rnode_cpu{cpu=\u0026quot;cpu0\u0026quot;,mode=\u0026quot;idle\u0026quot;} 362812.7890625\r# HELP node_load1 1m load average.\r# TYPE node_load1 gauge\rnode_load1 3.0703125\r 其中非#开头的每一行表示当前Node Exporter采集到的一个监控样本：node_cpu和node_load1表明了当前指标的名称、大括号中的标签则反映了当前样本的一些特征和维度、浮点数则是该监控样本的具体值。\n样本 Prometheus将所有的样本数据以时间序列(time-series)的方式存放在内存里，并定时保存到硬盘上。\ntime-series是按照时间戳和值的序列顺序存放的，我们称之为向量(vector). 每条time-series通过指标名称(metrics name)和一组标签集(labelset)命名。如下所示，可以将time-series理解为一个以时间为Y轴的数字矩阵：\n ^\r│ . . . . . . . . . . . . . . . . . . . node_cpu{cpu=\u0026quot;cpu0\u0026quot;,mode=\u0026quot;idle\u0026quot;}\r│ . . . . . . . . . . . . . . . . . . . node_cpu{cpu=\u0026quot;cpu0\u0026quot;,mode=\u0026quot;system\u0026quot;}\r│ . . . . . . . . . . . . . . . . . . node_load1{}\r│ . . . . . . . . . . . . . . . . . . v\r\u0026lt;------------------ 时间 ----------------\u0026gt;\r 在time-series中的每一个点称为一个样本（sample），样本由以下三部分组成：\n 指标(metric)：metric name和描述当前样本特征的labelsets; 时间戳(timestamp)：一个精确到毫秒的时间戳; 样本值(value)： 一个float64的浮点型数据表示当前样本的值。  \u0026lt;--------------- metric ---------------------\u0026gt;\u0026lt;-timestamp -\u0026gt;\u0026lt;-value-\u0026gt;\rhttp_request_total{status=\u0026quot;200\u0026quot;, method=\u0026quot;GET\u0026quot;}@1434417560938 =\u0026gt; 94355\rhttp_request_total{status=\u0026quot;200\u0026quot;, method=\u0026quot;GET\u0026quot;}@1434417561287 =\u0026gt; 94334\rhttp_request_total{status=\u0026quot;404\u0026quot;, method=\u0026quot;GET\u0026quot;}@1434417560938 =\u0026gt; 38473\rhttp_request_total{status=\u0026quot;404\u0026quot;, method=\u0026quot;GET\u0026quot;}@1434417561287 =\u0026gt; 38544\rhttp_request_total{status=\u0026quot;200\u0026quot;, method=\u0026quot;POST\u0026quot;}@1434417560938 =\u0026gt; 4748\rhttp_request_total{status=\u0026quot;200\u0026quot;, method=\u0026quot;POST\u0026quot;}@1434417561287 =\u0026gt; 4785\r 指标(Metric) 在形式上，所有的指标(Metric)都通过如下格式标示：\n\u0026lt;metric name\u0026gt;{\u0026lt;label name\u0026gt;=\u0026lt;label value\u0026gt;, ...}\r 指标的名称(metric name)可以反映被监控样本的含义（比如，http_request_total - 表示当前系统接收到的HTTP请求总量）。指标名称只能由ASCII字符、数字、下划线以及冒号组成并必须符合正则表达式[a-zA-Z_:][a-zA-Z0-9_:]*。\n标签(label)反映了当前样本的特征维度，通过这些维度Prometheus可以对样本数据进行过滤，聚合等。标签的名称只能由ASCII字符、数字以及下划线组成并满足正则表达式[a-zA-Z_][a-zA-Z0-9_]*。\n其中以__作为前缀的标签，是系统保留的关键字，只能在系统内部使用。标签的值则可以包含任何Unicode编码的字符。在Prometheus的底层实现中指标名称实际上是以__name__=的形式保存在数据库中的，因此以下两种方式均表示的同一条time-series：\napi_http_requests_total{method=\u0026quot;POST\u0026quot;, handler=\u0026quot;/messages\u0026quot;}\r 等同于：\n{__name__=\u0026quot;api_http_requests_total\u0026quot;，method=\u0026quot;POST\u0026quot;, handler=\u0026quot;/messages\u0026quot;}\r 在Prometheus源码中也可以找到指标(Metric)对应的数据结构，如下所示：\ntype Metric LabelSet\rtype LabelSet map[LabelName]LabelValue\rtype LabelName string\rtype LabelValue string\r 数据类型 Counter:只增不减的计数器  一般在定义Counter类型指标的名称时推荐使用_total作为后缀,如http_requests_total，node_cpu都是Counter类型的监控指标  Gauge: 可增可减的仪表盘  Gauge类型的指标侧重于反应系统的当前状态。因此这类指标的样本数据可增可减。常见指标如：node_memory_MemFree（主机当前空闲的内容大小）、node_memory_MemAvailable（可用内存大小）都是Gauge类型的监控指标。通过Gauge指标，用户可以直接查看系统的当前状态node_memory_MemFree  Summary \u0026amp;\u0026amp; Histogram   适用于一般使用于解决长尾问题\n  Histogram 统计数据的分部情况。比如最小值，最大值，中间值，中位数，75百分位，90百分位，95/98/99/99.9百分位的值（percentlies）\n这是一种特殊的 metrics 数据类型，代表的是一种 近似的百分比估算值\n  Summary和Histogram十分相似，常用于跟踪事件发生的规模，例如：请求耗时、响应大小。同样提供 count 和 sum 全部值的功能。例如：count=7次，sum=7次的值求值。 它提供一个quantiles的功能，可以按%比划分跟踪的结果。例如：quantile取值0.95，表示取采样值里面的95%数据。  **同时对于Histogram的指标，我们还可以通过histogram_quantile()函数计算出其值的分位数。不同在于Histogram通过histogram_quantile函数是在服务器端计算的分位数。 而Sumamry的分位数则是直接在客户端计算完成。因此对于分位数的计算而言，Summary在通过PromQL进行查询时有更好的性能表现，而Histogram则会消耗更多的资源。反之对于客户端而言Histogram消耗的资源更少。在选择这两种方式时用户应该按照自己的实际场景进行选择。**  Promql查询 查询时间序列  精确匹配：== != 正则匹配 =~ !~  http_requests_total{environment=~\u0026quot;staging|testing|development\u0026quot;,method!=\u0026quot;GET\u0026quot;}\n范围查询 我们通过``http_requests_total`查询，返回值中只会包含该时间序列中的最新的一个样本值，这样的返回结果我们称为**__瞬时向量__**,而相应的这样的表达式称之为__瞬时向量表达式__.\n如果想去查询一段时间内的样本数据时，我们则需要__区间向量表达式__http_requests_total{}[5m],区间向量单位：\n s - 秒 m - 分钟 h - 小时 d - 天 w - 周 y - 年  时间位移查询 关键字 offset\nhttp_request_total{} offset 5m //5分钟前的瞬时向量\rhttp_request_total{}[1d] offset 1d //昨天一天内的区间向量\r 聚合操作 Prometheus还提供了下列内置的聚合操作符，这些操作符作用域瞬时向量。可以将瞬时表达式返回的样本数据进行聚合，形成一个新的时间序列。\n\u0026lt;aggr-op\u0026gt;([parameter,] \u0026lt;vector expression\u0026gt;) [without|by (\u0026lt;label list\u0026gt;)]\r  sum (求和) min (最小值) max (最大值) avg (平均值) stddev (标准差) stdvar (标准方差) count (计数) count_values (对value进行计数) bottomk (后n条时序) topk (前n条时序) quantile (分位数)  例子：\n##计算k8s节点cpu资源\ravg (irate(node_cpu_seconds_total[15m]) )by (instance)\r##第一步：\rirate(node_cpu_secondes_total[15m] )获取瞬时向量\r### 第二步：by instance 及把所有instance相同的metric 放在一起取平均值\ravg (irate(node_cpu_seconds_total[15m]) )by (instance)\r ","id":21,"section":"posts","summary":"title: \u0026quot;Prometheus（一）\u0026quot; date: 2020-08-16T11:59:59+08:00 tags: [监控,prometheus] categories: [云原生] description: \u0026quot;Promethues笔记\u0026","tags":null,"title":"","uri":"https://zhangshunping.github.io/1/01/prometheus%E4%B8%80/","year":"0001"},{"content":"vue指令 v-on 指令 : 为元素绑定事件 \u0026lt;div id=\u0026quot;app\u0026quot;\u0026gt;\r\u0026lt;input type=\u0026quot;button\u0026quot; value=\u0026quot;vue-on\u0026quot; @click=\u0026quot;doIt\u0026quot;\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;script\u0026gt;s\rnew Vue({\rel: '#app',\rmethods: {\rdoIt:function () {\ralert(\u0026quot;do it \u0026quot;)\r}\r}\r})\r\u0026lt;/script\u0026gt;\r   v-on 通过改变数据来实现dom\n\u0026lt;div id=\u0026quot;app\u0026quot;\u0026gt;\r\u0026lt;input type=\u0026quot;button\u0026quot; value=\u0026quot;ChangeMes\u0026quot; @click=\u0026quot;ChangeName\u0026quot;\u0026gt;\r\u0026lt;h1 v-text=\u0026quot;mes\u0026quot;\u0026gt;\u0026lt;/h1\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;script\u0026gt;\rnew Vue({\rel: '#app',\rdata: {\rmes: 'hello World!',\r},\rmethods:{\rChangeName:function () {\rthis.mes=\u0026quot;apple\u0026quot;\r}\r}\r})\r\u0026lt;/script\u0026gt;\r   本地应用   计数器\n\u0026lt;div id=\u0026quot;app\u0026quot; \u0026gt;\r\u0026lt;button @click=\u0026quot;sub\u0026quot;\u0026gt;-\u0026lt;/button\u0026gt;\r\u0026lt;span v-text=\u0026quot;mes\u0026quot;\u0026gt;\u0026lt;/span\u0026gt;\r\u0026lt;button @click=\u0026quot;add\u0026quot;\u0026gt;+\u0026lt;/button\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;script\u0026gt;\rnew Vue({\rel: '#app',\rdata: {\rmes: 1,\r},\rmethods:{\rsub:function () {\rif (this.mes\u0026gt;0){\rthis.mes-=1;\r}else{\ralert(this.mes+\u0026quot;已经是最小值0\u0026quot;)\r}\r},\radd:function () {\rif (this.mes\u0026lt;10){\rthis.mes+=1\r}else{\ralert(this.mes+\u0026quot;已经是最大值10\u0026quot;)\r}\r}\r}\r})\r\u0026lt;/script\u0026gt;\r   ","id":22,"section":"posts","summary":"vue指令 v-on 指令 : 为元素绑定事件 \u0026lt;div id=\u0026quot;app\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;button\u0026quot; value=\u0026quot;vue-on\u0026quot; @click=\u0026quot;doIt\u0026quot;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script\u0026gt;s new Vue({ el: '#app', methods: { doIt:function () { alert(\u0026quot;do it \u0026quot;) } } }) \u0026lt;/script\u0026gt; v-on 通过改变数据来实现dom \u0026lt;div id=\u0026quot;app\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;button\u0026quot; value=\u0026quot;ChangeMes\u0026quot; @click=\u0026quot;ChangeName\u0026quot;\u0026gt; \u0026lt;h1 v-text=\u0026quot;mes\u0026quot;\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; new Vue({ el: '#app', data: { mes:","tags":null,"title":"","uri":"https://zhangshunping.github.io/1/01/vue%E4%B8%80/","year":"0001"}],"tags":[{"title":"awk","uri":"https://zhangshunping.github.io/tags/awk/"},{"title":"Gin","uri":"https://zhangshunping.github.io/tags/gin/"},{"title":"golang","uri":"https://zhangshunping.github.io/tags/golang/"},{"title":"golang-channel","uri":"https://zhangshunping.github.io/tags/golang-channel/"},{"title":"iptables","uri":"https://zhangshunping.github.io/tags/iptables/"},{"title":"kubernetes","uri":"https://zhangshunping.github.io/tags/kubernetes/"},{"title":"linux","uri":"https://zhangshunping.github.io/tags/linux/"},{"title":"prometheus","uri":"https://zhangshunping.github.io/tags/prometheus/"},{"title":"Python","uri":"https://zhangshunping.github.io/tags/python/"},{"title":"rync","uri":"https://zhangshunping.github.io/tags/rync/"},{"title":"监控","uri":"https://zhangshunping.github.io/tags/%E7%9B%91%E6%8E%A7/"}]}